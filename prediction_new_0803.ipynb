{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wk/w4dq25x94cg_26_p83q6tnlh0000gn/T/ipykernel_12561/2502907041.py:1: DtypeWarning: Columns (9,31,33,35,46) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_reg = pd.read_csv(\"merged_data_2018.csv\")\n"
     ]
    }
   ],
   "source": [
    "df_reg = pd.read_csv(\"merged_data_2018.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bldgclass</th>\n",
       "      <th>landuse</th>\n",
       "      <th>proxcode</th>\n",
       "      <th>bsmtcode</th>\n",
       "      <th>assessland</th>\n",
       "      <th>assesstot</th>\n",
       "      <th>exempttot</th>\n",
       "      <th>yearalter1</th>\n",
       "      <th>yearalter2</th>\n",
       "      <th>landmark</th>\n",
       "      <th>...</th>\n",
       "      <th>days_pending</th>\n",
       "      <th>market_heat</th>\n",
       "      <th>new_construction_sale</th>\n",
       "      <th>sales_count</th>\n",
       "      <th>nyur</th>\n",
       "      <th>redfunds</th>\n",
       "      <th>GDP</th>\n",
       "      <th>median_income</th>\n",
       "      <th>cpi</th>\n",
       "      <th>bldgclass_letter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16680.0</td>\n",
       "      <td>77760.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1989.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>415.0</td>\n",
       "      <td>16754.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.56</td>\n",
       "      <td>26272.011</td>\n",
       "      <td>78920.0</td>\n",
       "      <td>7.99264</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>297000.0</td>\n",
       "      <td>1264500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>20756.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.33</td>\n",
       "      <td>26272.011</td>\n",
       "      <td>78920.0</td>\n",
       "      <td>7.99264</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>297000.0</td>\n",
       "      <td>1264500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>20756.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.33</td>\n",
       "      <td>26272.011</td>\n",
       "      <td>78920.0</td>\n",
       "      <td>7.99264</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>150750.0</td>\n",
       "      <td>815400.0</td>\n",
       "      <td>815400.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>415.0</td>\n",
       "      <td>16754.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.56</td>\n",
       "      <td>26272.011</td>\n",
       "      <td>78920.0</td>\n",
       "      <td>7.99264</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>122850.0</td>\n",
       "      <td>2337120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>517.0</td>\n",
       "      <td>20756.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.33</td>\n",
       "      <td>26272.011</td>\n",
       "      <td>78920.0</td>\n",
       "      <td>7.99264</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  bldgclass  landuse  proxcode  bsmtcode  assessland  assesstot  exempttot  \\\n",
       "0        A4      1.0       3.0       1.0     16680.0    77760.0        0.0   \n",
       "1        C1      2.0       3.0       0.0    297000.0  1264500.0        0.0   \n",
       "2        C1      2.0       3.0       0.0    297000.0  1264500.0        0.0   \n",
       "3        C4      2.0       3.0       2.0    150750.0   815400.0   815400.0   \n",
       "4        C7      4.0       3.0       2.0    122850.0  2337120.0        0.0   \n",
       "\n",
       "   yearalter1  yearalter2 landmark  ...  days_pending  market_heat  \\\n",
       "0      1989.0         0.0      NaN  ...          53.0         61.0   \n",
       "1      2011.0         0.0      NaN  ...          50.0         66.0   \n",
       "2      2011.0         0.0      NaN  ...          50.0         66.0   \n",
       "3      2009.0         0.0      NaN  ...          53.0         61.0   \n",
       "4         0.0      2009.0      NaN  ...          50.0         66.0   \n",
       "\n",
       "   new_construction_sale  sales_count  nyur  redfunds        GDP  \\\n",
       "0                  415.0      16754.0   3.9      2.56  26272.011   \n",
       "1                  517.0      20756.0   3.8      2.33  26272.011   \n",
       "2                  517.0      20756.0   3.8      2.33  26272.011   \n",
       "3                  415.0      16754.0   3.9      2.56  26272.011   \n",
       "4                  517.0      20756.0   3.8      2.33  26272.011   \n",
       "\n",
       "   median_income      cpi  bldgclass_letter  \n",
       "0        78920.0  7.99264                 A  \n",
       "1        78920.0  7.99264                 C  \n",
       "2        78920.0  7.99264                 C  \n",
       "3        78920.0  7.99264                 C  \n",
       "4        78920.0  7.99264                 C  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### tutaj sprawdzam na wplyw outlierow na sale price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "col = 'sale price'\n",
    "\n",
    "Q1 = df_reg[col].quantile(0.25)\n",
    "Q3 = df_reg[col].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "df_clean = df_reg[(df_reg[col] >= lower_bound) & (df_reg[col] <= upper_bound)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2.378320e+05\n",
       "mean     6.812092e+05\n",
       "std      3.936725e+05\n",
       "min      1.000000e+00\n",
       "25%      3.940000e+05\n",
       "50%      6.350000e+05\n",
       "75%      9.000000e+05\n",
       "max      1.867500e+06\n",
       "Name: sale price, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean[\"sale price\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2.618670e+05\n",
       "mean     1.206654e+06\n",
       "std      5.611312e+06\n",
       "min      1.000000e+00\n",
       "25%      4.200000e+05\n",
       "50%      6.800000e+05\n",
       "75%      9.990000e+05\n",
       "max      8.696129e+08\n",
       "Name: sale price, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reg[\"sale price\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### jezeli to zrobimy to dzialamy na datasecie bez outlierow - jesli nie to nie odpalaj ponizszej komorki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional\n",
    "df_reg = df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg[\"sale_date\"] = pd.to_datetime(df_reg[\"sale_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg['sale_year'] = df_reg['sale_date'].dt.year\n",
    "df_reg['sale_month'] = df_reg['sale_date'].dt.month\n",
    "df_reg['sale_day'] = df_reg['sale_date'].dt.day\n",
    "df_reg['sale_weekday'] = df_reg['sale_date'].dt.weekday  # Monday=0, Sunday=6\n",
    "df_reg['sale_quarter'] = df_reg['sale_date'].dt.quarter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wybor zmiennych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = [\n",
    "    \"bldgclass\", \"building class category\", \"building class at present\", \n",
    "    \"sale date\", \"Date\", \"month_end\", \"ease-ment\", \"apartment number\", \n",
    "    \"block\", \"lot\", 'tax class at present', 'building class at time of sale', \n",
    "    \"sale_date\"]\n",
    "numeric_features = [\n",
    "    # Continuous/Count variables\n",
    "    'assessland', 'assesstot', 'exempttot', 'builtfar', 'residfar', 'commfar', 'facilfar',\n",
    "    'land square feet', 'gross square feet', 'zhvi', 'zori', 'zordi',\n",
    "    'inventory', 'days_pending', 'market_heat', 'sales_count', 'GDP', 'median_income', 'cpi',\n",
    "    # Additional numeric (if applicable)\n",
    "    'easements',\n",
    "\n",
    "    'residential units', 'commercial units', 'total units',\n",
    "    'year built',\n",
    "\n",
    "    \"sale_year\", \"sale_month\", \"sale_day\", \"sale_weekday\", \"sale_quarter\",\n",
    "    # jak robisz autogluon to odkomentuj sale price\n",
    "    \"sale price\" \n",
    "]\n",
    "\n",
    "# Boolean (Flag) variables - often numeric (0/1 or many zeros/missing) in nature\n",
    "boolean_features = [\n",
    "    'firm07_flag', 'pfirm15_flag', 'changed_building_class',\n",
    "    'new_listing', 'new_pendly_listing', 'new_construction_sale',\n",
    "    'yearalter1', 'yearalter2', 'ltdheight',\n",
    "    'zonedist1', 'zonedist2', 'overlay1', 'overlay2',\n",
    "    'spdist1', 'spdist2','landmark', 'ownertype',\n",
    "]\n",
    "\n",
    "# Object (Categorical) variables\n",
    "categorical_features = [\n",
    "    'firecomp', 'sanitsub', 'neighborhood',\n",
    "    'bldgclass_letter',\n",
    "    # Identifier/Code variables (numeric but likely categorical)\n",
    "    'landuse', 'proxcode', 'bsmtcode', 'lottype', 'cd', 'schooldist', 'council',\n",
    "    'policeprct', 'healthcenterdistrict', 'healtharea', 'sanitboro', 'sanitdistrict',\n",
    "    ' zip code',  # note: zip code is numeric but typically categorical\n",
    "    'tax class at time of sale', 'buidling_class_num',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = df_reg.drop(columns=to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['landuse', 'proxcode', 'bsmtcode', 'assessland', 'assesstot',\n",
       "       'exempttot', 'yearalter1', 'yearalter2', 'landmark', 'builtfar',\n",
       "       'residfar', 'commfar', 'facilfar', 'lottype', 'condono', 'cd',\n",
       "       'firm07_flag', 'pfirm15_flag', 'schooldist', 'council', 'firecomp',\n",
       "       'policeprct', 'healthcenterdistrict', 'healtharea', 'sanitboro',\n",
       "       'sanitdistrict', 'sanitsub', 'zonedist1', 'zonedist2', 'overlay1',\n",
       "       'overlay2', 'spdist1', 'spdist2', 'spdist3', 'ltdheight', 'easements',\n",
       "       'ownertype', 'borough', 'neighborhood', ' zip code',\n",
       "       'residential units', 'commercial units', 'total units',\n",
       "       'land square feet', 'gross square feet', 'year built',\n",
       "       'tax class at time of sale', 'sale price', 'buidling_class_num',\n",
       "       'changed_building_class', 'zhvi', 'zori', 'zordi', 'inventory',\n",
       "       'new_listing', 'new_pendly_listing', 'days_pending', 'market_heat',\n",
       "       'new_construction_sale', 'sales_count', 'nyur', 'redfunds', 'GDP',\n",
       "       'median_income', 'cpi', 'bldgclass_letter', 'sale_year', 'sale_month',\n",
       "       'sale_day', 'sale_weekday', 'sale_quarter'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reg.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformacje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do zmiennych numerycznych"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Klasa ktora obcina outliery poza 1 i 99 percentylem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutlierClipper(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Clips values in each column to lie between the lower and upper quantile thresholds.\n",
    "    \"\"\"\n",
    "    def __init__(self, lower_quantile=0.01, upper_quantile=0.99):\n",
    "        self.lower_quantile = lower_quantile\n",
    "        self.upper_quantile = upper_quantile\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Compute the lower and upper bounds for each column\n",
    "        self.lower_bounds_ = np.nanpercentile(X, self.lower_quantile * 100, axis=0)\n",
    "        self.upper_bounds_ = np.nanpercentile(X, self.upper_quantile * 100, axis=0)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Clip values for each column based on computed bounds\n",
    "        return np.clip(X, self.lower_bounds_, self.upper_bounds_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Define a log transformation (using log1p to handle zeros safely)\n",
    "# to pomaga z mocno skrzywionymi rozkladami\n",
    "log_transformer = FunctionTransformer(np.log1p, validate=True)\n",
    "\n",
    "# Build a numeric pipeline that imputes, clips outliers, applies log transform, and scales.\n",
    "numeric_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),  # Fill missing values\n",
    "    ('outlier_clipper', OutlierClipper(lower_quantile=0.01, upper_quantile=0.99)),\n",
    "    ('log_transform', log_transformer),             # Apply log transform (if distributions are skewed)\n",
    "    ('scaler', StandardScaler())                    # Standardize features\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zmienne 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_binary(x):\n",
    "    # 0 if the value is null, 0, \"0\", or an empty string; otherwise 1.\n",
    "    def convert(val):\n",
    "        if pd.isnull(val) or val == 0 or val == '0' or val == '':\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "    # Vectorize the conversion to apply elementwise\n",
    "    vectorized_convert = np.vectorize(convert)\n",
    "    return vectorized_convert(x)\n",
    "\n",
    "boolean_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=0)),  # Fill missing values with 0\n",
    "    ('to_bool', FunctionTransformer(to_binary, validate=False))     # Convert to boolean (0/1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zmienne kategoryczne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Klasa do wartosci kategorycznych - jak jest ich mniej niz 20 000 (ok. 10% zbioru) to da other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RareCategoryGrouper(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Groups categories that appear less than min_frequency times as 'other'.\n",
    "    This transformer now accepts both pandas DataFrames and numpy arrays.\n",
    "    \"\"\"\n",
    "    def __init__(self, min_frequency=10):\n",
    "        self.min_frequency = min_frequency\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Convert to DataFrame if X is not one\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "        self.frequent_categories_ = {}\n",
    "        for col in X.columns:\n",
    "            counts = X[col].value_counts()\n",
    "            self.frequent_categories_[col] = counts[counts >= self.min_frequency].index.tolist()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Convert to DataFrame if needed\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "        X_transformed = X.copy()\n",
    "        for col in X_transformed.columns:\n",
    "            # Use get to provide an empty list if column wasn't seen during fit.\n",
    "            frequent = self.frequent_categories_.get(col, [])\n",
    "            X_transformed[col] = X_transformed[col].apply(lambda x: x if x in frequent else \"other\")\n",
    "        return X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('rare_grouper', RareCategoryGrouper(5000)),  # Adjust threshold as needed\n",
    "    ('to_string', FunctionTransformer(lambda x: x.astype(str))),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_pipeline, numeric_features),\n",
    "        ('bool', boolean_pipeline, boolean_features),\n",
    "        ('cat', categorical_pipeline, categorical_features),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sprawdzenie dzialania transformatorow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tutaj czy rzadkie kategorie sie zapisuja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>D</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  col1 col2\n",
       "0    A    X\n",
       "1    B    Y\n",
       "2    A    Z\n",
       "3    C    X\n",
       "4    D    X"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_array = np.array([['A', 'X'], ['B', 'Y'], ['A', 'Z'], ['C', 'X'], ['D', 'X']])\n",
    "sample_df = pd.DataFrame(sample_array, columns=['col1', 'col2'])\n",
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0      1\n",
      "0      A      X\n",
      "1  other  other\n",
      "2      A  other\n",
      "3  other      X\n",
      "4  other      X\n"
     ]
    }
   ],
   "source": [
    "rcg = RareCategoryGrouper(min_frequency=2)\n",
    "print(rcg.fit_transform(sample_df.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num1</th>\n",
       "      <th>num2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100000000.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          num1   num2\n",
       "0        100.0   10.0\n",
       "1        200.0   15.0\n",
       "2          NaN    0.0\n",
       "3  100000000.0  100.0\n",
       "4         50.0    NaN"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_sample = pd.DataFrame({\n",
    "    'num1': [100, 200, np.nan, 100000000, 50],\n",
    "    'num2': [10, 15, 0, 100, np.nan]\n",
    "})\n",
    "numeric_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tutaj czy dziala clip dla outlierow (clip != usuniecie wartosci tylko przeksztalcenie ich)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num1</th>\n",
       "      <th>num2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200.0</td>\n",
       "      <td>15.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97000006.0</td>\n",
       "      <td>97.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         num1   num2\n",
       "0       100.0  10.00\n",
       "1       200.0  15.00\n",
       "2         NaN   0.30\n",
       "3  97000006.0  97.45\n",
       "4        51.5    NaN"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OutlierClipper().fit_transform(numeric_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.51865539, -0.1039363 ],\n",
       "       [-0.3930663 ,  0.17382146],\n",
       "       [-0.44526398, -1.6320555 ],\n",
       "       [ 1.993318  ,  1.51429391],\n",
       "       [-0.63633233,  0.04787643]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_pipeline.fit_transform(numeric_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tutaj jak dzialaj kolumny 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bool_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LH-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>OtherValue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     bool_col\n",
       "0         NaN\n",
       "1           0\n",
       "2           0\n",
       "3            \n",
       "4        LH-1\n",
       "5  OtherValue\n",
       "6           5\n",
       "7            "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool_sample = pd.DataFrame({\n",
    "    'bool_col': [np.nan, 0, '0', '', 'LH-1', 'OtherValue', 5, '']\n",
    "})\n",
    "bool_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boolean_pipeline.fit_transform(bool_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kategorie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firecomp</th>\n",
       "      <th>sanitsub</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>bldgclass_letter</th>\n",
       "      <th>landuse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F1</td>\n",
       "      <td>S1</td>\n",
       "      <td>NB1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F1</td>\n",
       "      <td>S2</td>\n",
       "      <td>NB1</td>\n",
       "      <td>B</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F2</td>\n",
       "      <td>S2</td>\n",
       "      <td>NB2</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F3</td>\n",
       "      <td>S1</td>\n",
       "      <td>NB3</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F4</td>\n",
       "      <td>S1</td>\n",
       "      <td>NB1</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>F5</td>\n",
       "      <td>S3</td>\n",
       "      <td>NB2</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>F1</td>\n",
       "      <td>S3</td>\n",
       "      <td>NB2</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>F6</td>\n",
       "      <td>S3</td>\n",
       "      <td>NB3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>F6</td>\n",
       "      <td>S4</td>\n",
       "      <td>NB3</td>\n",
       "      <td>B</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>F6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NB3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>F7</td>\n",
       "      <td>S4</td>\n",
       "      <td>NB3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   firecomp sanitsub neighborhood bldgclass_letter landuse\n",
       "0        F1       S1          NB1                A       1\n",
       "1        F1       S2          NB1                B       2\n",
       "2        F2       S2          NB2                A       3\n",
       "3        F3       S1          NB3                C       2\n",
       "4        F4       S1          NB1                C       1\n",
       "5        F5       S3          NB2                C       1\n",
       "6        F1       S3          NB2                A       2\n",
       "7        F6       S3          NB3              NaN       3\n",
       "8        F6       S4          NB3                B       4\n",
       "9        F6      NaN          NB3                A       4\n",
       "10       F7       S4          NB3                A       4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_cat = pd.DataFrame({\n",
    "    'firecomp': ['F1', 'F1', 'F2', 'F3', 'F4', 'F5', 'F1', 'F6', 'F6', 'F6', 'F7'],\n",
    "    'sanitsub': ['S1', 'S2', 'S2', 'S1', 'S1', 'S3', 'S3', 'S3', 'S4', np.nan, 'S4'],\n",
    "    'neighborhood': ['NB1', 'NB1', 'NB2', 'NB3', 'NB1', 'NB2', 'NB2', 'NB3', 'NB3', 'NB3', 'NB3'],\n",
    "    'bldgclass_letter': ['A', 'B', 'A', 'C', 'C', 'C', 'A', np.nan, 'B', 'A', 'A'],\n",
    "    'landuse': ['1', '2', '3', '2', '1', '1', '2', '3', '4', '4', '4']\n",
    "})\n",
    "sample_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_pipeline2 = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('rare_grouper', RareCategoryGrouper(3)),  # Adjust threshold as needed\n",
    "    ('to_string', FunctionTransformer(lambda x: x.astype(str))),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_pipeline2.fit_transform(sample_cat).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x0_F1' 'x0_F6' 'x0_other' 'x1_S1' 'x1_S3' 'x1_other' 'x2_NB1' 'x2_NB2'\n",
      " 'x2_NB3' 'x3_A' 'x3_C' 'x3_other' 'x4_1' 'x4_2' 'x4_4' 'x4_other']\n"
     ]
    }
   ],
   "source": [
    "ohe = categorical_pipeline2.named_steps['onehot']\n",
    "\n",
    "# Retrieve the feature names generated by the encoder\n",
    "feature_names = ohe.get_feature_names_out()\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modele"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (166482, 177)\n",
      "X_val shape: (35675, 177)\n",
      "X_test shape: (35675, 177)\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import r2_score, root_mean_squared_error\n",
    "\n",
    "X = df_reg.drop(\"sale price\", axis=1)\n",
    "y = df_reg[\"sale price\"]\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# First fit the preprocessor on the training data\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "# Then transform validation and test sets\n",
    "X_val_transformed = preprocessor.transform(X_val)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "# Print shapes to confirm transformation was successful\n",
    "print(f\"X_train shape: {X_train_transformed.shape}\")\n",
    "print(f\"X_val shape: {X_val_transformed.shape}\")\n",
    "print(f\"X_test shape: {X_test_transformed.shape}\")\n",
    "\n",
    "train_data = lgb.Dataset(X_train_transformed, label=y_train)\n",
    "val_data = lgb.Dataset(X_val_transformed, label=y_val, reference=train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'num_leaves': 31,           # controls complexity; adjust based on your data\n",
    "    'learning_rate': 0.05,      # a smaller learning rate can improve accuracy but requires more rounds\n",
    "    'feature_fraction': 0.9,    # randomly select part of features on each iteration for robustness\n",
    "    'bagging_fraction': 0.8,    # randomly select part of data on each iteration for better generalization\n",
    "    'bagging_freq': 5,          # frequency for bagging; set to 0 to disable\n",
    "    'verbose': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 400 rounds\n",
      "[100]\ttrain's rmse: 272312\tvalidation's rmse: 275208\n",
      "[200]\ttrain's rmse: 263757\tvalidation's rmse: 269118\n",
      "[300]\ttrain's rmse: 258541\tvalidation's rmse: 266196\n",
      "[400]\ttrain's rmse: 254052\tvalidation's rmse: 263748\n",
      "[500]\ttrain's rmse: 250081\tvalidation's rmse: 262043\n",
      "[600]\ttrain's rmse: 246786\tvalidation's rmse: 260639\n",
      "[700]\ttrain's rmse: 243383\tvalidation's rmse: 259203\n",
      "[800]\ttrain's rmse: 240490\tvalidation's rmse: 258210\n",
      "[900]\ttrain's rmse: 237761\tvalidation's rmse: 257203\n",
      "[1000]\ttrain's rmse: 235234\tvalidation's rmse: 256391\n",
      "[1100]\ttrain's rmse: 232607\tvalidation's rmse: 255482\n",
      "[1200]\ttrain's rmse: 230222\tvalidation's rmse: 254783\n",
      "[1300]\ttrain's rmse: 228153\tvalidation's rmse: 254237\n",
      "[1400]\ttrain's rmse: 225915\tvalidation's rmse: 253685\n",
      "[1500]\ttrain's rmse: 223646\tvalidation's rmse: 252954\n",
      "[1600]\ttrain's rmse: 221655\tvalidation's rmse: 252371\n",
      "[1700]\ttrain's rmse: 219552\tvalidation's rmse: 251845\n",
      "[1800]\ttrain's rmse: 217635\tvalidation's rmse: 251383\n",
      "[1900]\ttrain's rmse: 215821\tvalidation's rmse: 250962\n",
      "[2000]\ttrain's rmse: 213962\tvalidation's rmse: 250529\n",
      "[2100]\ttrain's rmse: 212238\tvalidation's rmse: 250079\n",
      "[2200]\ttrain's rmse: 210493\tvalidation's rmse: 249722\n",
      "[2300]\ttrain's rmse: 208774\tvalidation's rmse: 249362\n",
      "[2400]\ttrain's rmse: 207043\tvalidation's rmse: 249033\n",
      "[2500]\ttrain's rmse: 205431\tvalidation's rmse: 248717\n",
      "[2600]\ttrain's rmse: 203792\tvalidation's rmse: 248342\n",
      "[2700]\ttrain's rmse: 202345\tvalidation's rmse: 248088\n",
      "[2800]\ttrain's rmse: 200910\tvalidation's rmse: 247840\n",
      "[2900]\ttrain's rmse: 199376\tvalidation's rmse: 247587\n",
      "[3000]\ttrain's rmse: 197931\tvalidation's rmse: 247317\n",
      "[3100]\ttrain's rmse: 196541\tvalidation's rmse: 247084\n",
      "[3200]\ttrain's rmse: 195256\tvalidation's rmse: 246867\n",
      "[3300]\ttrain's rmse: 193946\tvalidation's rmse: 246684\n",
      "[3400]\ttrain's rmse: 192631\tvalidation's rmse: 246486\n",
      "[3500]\ttrain's rmse: 191328\tvalidation's rmse: 246197\n",
      "[3600]\ttrain's rmse: 190037\tvalidation's rmse: 246020\n",
      "[3700]\ttrain's rmse: 188888\tvalidation's rmse: 245818\n",
      "[3800]\ttrain's rmse: 187752\tvalidation's rmse: 245644\n",
      "[3900]\ttrain's rmse: 186562\tvalidation's rmse: 245464\n",
      "[4000]\ttrain's rmse: 185440\tvalidation's rmse: 245302\n",
      "[4100]\ttrain's rmse: 184280\tvalidation's rmse: 245112\n",
      "[4200]\ttrain's rmse: 183164\tvalidation's rmse: 244970\n",
      "[4300]\ttrain's rmse: 182086\tvalidation's rmse: 244822\n",
      "[4400]\ttrain's rmse: 180908\tvalidation's rmse: 244557\n",
      "[4500]\ttrain's rmse: 179863\tvalidation's rmse: 244460\n",
      "[4600]\ttrain's rmse: 178743\tvalidation's rmse: 244310\n",
      "[4700]\ttrain's rmse: 177735\tvalidation's rmse: 244257\n",
      "[4800]\ttrain's rmse: 176699\tvalidation's rmse: 244112\n",
      "[4900]\ttrain's rmse: 175670\tvalidation's rmse: 244002\n",
      "[5000]\ttrain's rmse: 174695\tvalidation's rmse: 243899\n",
      "[5100]\ttrain's rmse: 173681\tvalidation's rmse: 243755\n",
      "[5200]\ttrain's rmse: 172674\tvalidation's rmse: 243608\n",
      "[5300]\ttrain's rmse: 171695\tvalidation's rmse: 243427\n",
      "[5400]\ttrain's rmse: 170716\tvalidation's rmse: 243308\n",
      "[5500]\ttrain's rmse: 169761\tvalidation's rmse: 243155\n",
      "[5600]\ttrain's rmse: 168852\tvalidation's rmse: 243089\n",
      "[5700]\ttrain's rmse: 167854\tvalidation's rmse: 242978\n",
      "[5800]\ttrain's rmse: 166918\tvalidation's rmse: 242925\n",
      "[5900]\ttrain's rmse: 166058\tvalidation's rmse: 242842\n",
      "[6000]\ttrain's rmse: 165158\tvalidation's rmse: 242758\n",
      "[6100]\ttrain's rmse: 164255\tvalidation's rmse: 242635\n",
      "[6200]\ttrain's rmse: 163355\tvalidation's rmse: 242559\n",
      "[6300]\ttrain's rmse: 162510\tvalidation's rmse: 242474\n",
      "[6400]\ttrain's rmse: 161672\tvalidation's rmse: 242378\n",
      "[6500]\ttrain's rmse: 160781\tvalidation's rmse: 242242\n",
      "[6600]\ttrain's rmse: 159931\tvalidation's rmse: 242186\n",
      "[6700]\ttrain's rmse: 159138\tvalidation's rmse: 242098\n",
      "[6800]\ttrain's rmse: 158344\tvalidation's rmse: 242033\n",
      "[6900]\ttrain's rmse: 157509\tvalidation's rmse: 241939\n",
      "[7000]\ttrain's rmse: 156722\tvalidation's rmse: 241866\n",
      "[7100]\ttrain's rmse: 155947\tvalidation's rmse: 241755\n",
      "[7200]\ttrain's rmse: 155183\tvalidation's rmse: 241634\n",
      "[7300]\ttrain's rmse: 154402\tvalidation's rmse: 241582\n",
      "[7400]\ttrain's rmse: 153614\tvalidation's rmse: 241508\n",
      "[7500]\ttrain's rmse: 152868\tvalidation's rmse: 241434\n",
      "[7600]\ttrain's rmse: 152110\tvalidation's rmse: 241389\n",
      "[7700]\ttrain's rmse: 151325\tvalidation's rmse: 241359\n",
      "[7800]\ttrain's rmse: 150550\tvalidation's rmse: 241323\n",
      "[7900]\ttrain's rmse: 149863\tvalidation's rmse: 241225\n",
      "[8000]\ttrain's rmse: 149123\tvalidation's rmse: 241195\n",
      "[8100]\ttrain's rmse: 148417\tvalidation's rmse: 241159\n",
      "[8200]\ttrain's rmse: 147764\tvalidation's rmse: 241112\n",
      "[8300]\ttrain's rmse: 147032\tvalidation's rmse: 241040\n",
      "[8400]\ttrain's rmse: 146358\tvalidation's rmse: 240958\n",
      "[8500]\ttrain's rmse: 145681\tvalidation's rmse: 240895\n",
      "[8600]\ttrain's rmse: 144992\tvalidation's rmse: 240830\n",
      "[8700]\ttrain's rmse: 144317\tvalidation's rmse: 240761\n",
      "[8800]\ttrain's rmse: 143638\tvalidation's rmse: 240708\n",
      "[8900]\ttrain's rmse: 143000\tvalidation's rmse: 240657\n",
      "[9000]\ttrain's rmse: 142343\tvalidation's rmse: 240643\n",
      "[9100]\ttrain's rmse: 141718\tvalidation's rmse: 240658\n",
      "[9200]\ttrain's rmse: 141070\tvalidation's rmse: 240660\n",
      "[9300]\ttrain's rmse: 140458\tvalidation's rmse: 240615\n",
      "[9400]\ttrain's rmse: 139862\tvalidation's rmse: 240554\n",
      "[9500]\ttrain's rmse: 139229\tvalidation's rmse: 240503\n",
      "[9600]\ttrain's rmse: 138601\tvalidation's rmse: 240424\n",
      "[9700]\ttrain's rmse: 137984\tvalidation's rmse: 240366\n",
      "[9800]\ttrain's rmse: 137393\tvalidation's rmse: 240314\n",
      "[9900]\ttrain's rmse: 136806\tvalidation's rmse: 240306\n",
      "[10000]\ttrain's rmse: 136194\tvalidation's rmse: 240283\n",
      "[10100]\ttrain's rmse: 135619\tvalidation's rmse: 240238\n",
      "[10200]\ttrain's rmse: 135072\tvalidation's rmse: 240235\n",
      "[10300]\ttrain's rmse: 134498\tvalidation's rmse: 240180\n",
      "[10400]\ttrain's rmse: 133896\tvalidation's rmse: 240144\n",
      "[10500]\ttrain's rmse: 133328\tvalidation's rmse: 240121\n",
      "[10600]\ttrain's rmse: 132751\tvalidation's rmse: 240104\n",
      "[10700]\ttrain's rmse: 132202\tvalidation's rmse: 240042\n",
      "[10800]\ttrain's rmse: 131631\tvalidation's rmse: 240010\n",
      "[10900]\ttrain's rmse: 131138\tvalidation's rmse: 239945\n",
      "[11000]\ttrain's rmse: 130568\tvalidation's rmse: 239885\n",
      "[11100]\ttrain's rmse: 130011\tvalidation's rmse: 239823\n",
      "[11200]\ttrain's rmse: 129484\tvalidation's rmse: 239792\n",
      "[11300]\ttrain's rmse: 128945\tvalidation's rmse: 239758\n",
      "[11400]\ttrain's rmse: 128370\tvalidation's rmse: 239715\n",
      "[11500]\ttrain's rmse: 127874\tvalidation's rmse: 239696\n",
      "[11600]\ttrain's rmse: 127337\tvalidation's rmse: 239653\n",
      "[11700]\ttrain's rmse: 126799\tvalidation's rmse: 239637\n",
      "[11800]\ttrain's rmse: 126275\tvalidation's rmse: 239607\n",
      "[11900]\ttrain's rmse: 125783\tvalidation's rmse: 239601\n",
      "[12000]\ttrain's rmse: 125265\tvalidation's rmse: 239589\n",
      "[12100]\ttrain's rmse: 124727\tvalidation's rmse: 239552\n",
      "[12200]\ttrain's rmse: 124222\tvalidation's rmse: 239545\n",
      "[12300]\ttrain's rmse: 123714\tvalidation's rmse: 239472\n",
      "[12400]\ttrain's rmse: 123174\tvalidation's rmse: 239479\n",
      "[12500]\ttrain's rmse: 122660\tvalidation's rmse: 239459\n",
      "[12600]\ttrain's rmse: 122200\tvalidation's rmse: 239418\n",
      "[12700]\ttrain's rmse: 121718\tvalidation's rmse: 239393\n",
      "[12800]\ttrain's rmse: 121219\tvalidation's rmse: 239412\n",
      "[12900]\ttrain's rmse: 120707\tvalidation's rmse: 239364\n",
      "[13000]\ttrain's rmse: 120238\tvalidation's rmse: 239331\n",
      "[13100]\ttrain's rmse: 119755\tvalidation's rmse: 239300\n",
      "[13200]\ttrain's rmse: 119271\tvalidation's rmse: 239266\n",
      "[13300]\ttrain's rmse: 118793\tvalidation's rmse: 239229\n",
      "[13400]\ttrain's rmse: 118337\tvalidation's rmse: 239185\n",
      "[13500]\ttrain's rmse: 117896\tvalidation's rmse: 239187\n",
      "[13600]\ttrain's rmse: 117414\tvalidation's rmse: 239156\n",
      "[13700]\ttrain's rmse: 116933\tvalidation's rmse: 239109\n",
      "[13800]\ttrain's rmse: 116447\tvalidation's rmse: 239093\n",
      "[13900]\ttrain's rmse: 115987\tvalidation's rmse: 239073\n",
      "[14000]\ttrain's rmse: 115503\tvalidation's rmse: 239057\n",
      "[14100]\ttrain's rmse: 115064\tvalidation's rmse: 239023\n",
      "[14200]\ttrain's rmse: 114630\tvalidation's rmse: 238996\n",
      "[14300]\ttrain's rmse: 114191\tvalidation's rmse: 238981\n",
      "[14400]\ttrain's rmse: 113766\tvalidation's rmse: 238968\n",
      "[14500]\ttrain's rmse: 113326\tvalidation's rmse: 238927\n",
      "[14600]\ttrain's rmse: 112883\tvalidation's rmse: 238896\n",
      "[14700]\ttrain's rmse: 112464\tvalidation's rmse: 238885\n",
      "[14800]\ttrain's rmse: 112033\tvalidation's rmse: 238858\n",
      "[14900]\ttrain's rmse: 111619\tvalidation's rmse: 238848\n",
      "[15000]\ttrain's rmse: 111212\tvalidation's rmse: 238832\n",
      "[15100]\ttrain's rmse: 110813\tvalidation's rmse: 238846\n",
      "[15200]\ttrain's rmse: 110383\tvalidation's rmse: 238814\n",
      "[15300]\ttrain's rmse: 109985\tvalidation's rmse: 238823\n",
      "[15400]\ttrain's rmse: 109577\tvalidation's rmse: 238833\n",
      "[15500]\ttrain's rmse: 109139\tvalidation's rmse: 238826\n",
      "[15600]\ttrain's rmse: 108729\tvalidation's rmse: 238810\n",
      "Early stopping, best iteration is:\n",
      "[15248]\ttrain's rmse: 110164\tvalidation's rmse: 238796\n"
     ]
    }
   ],
   "source": [
    "model = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    num_boost_round=20000,\n",
    "    valid_sets=[train_data, val_data],\n",
    "    valid_names=['train', 'validation'],\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(400), \n",
    "        lgb.log_evaluation(100)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "238795.75683755052 0.6346433411552408\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_val_transformed, num_iteration=model.best_iteration)\n",
    "rmse = root_mean_squared_error(y_val, y_pred)\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "print(rmse, r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6266782964053643"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test = model.predict(X_test_transformed, num_iteration=model.best_iteration)\n",
    "r2_test = r2_score(y_test, y_pred_test)\n",
    "r2_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### AUTOGLUON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patryk/venv-torch/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_reg\n",
    "\n",
    "X_train, X_temp= train_test_split(X, test_size=0.3, random_state=42)\n",
    "X_val, X_test= train_test_split(X_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trening bez outlierow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20250308_144906\"\n",
      "Verbosity: 3 (Detailed Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.9.6\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 24.3.0: Thu Jan  2 20:24:24 PST 2025; root:xnu-11215.81.4~3/RELEASE_ARM64_T6030\n",
      "CPU Count:          11\n",
      "GPU Count:          0\n",
      "Memory Avail:       6.59 GB / 18.00 GB (36.6%)\n",
      "Disk Space Avail:   32.78 GB / 460.43 GB (7.1%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "============ fit kwarg info ============\n",
      "User Specified kwargs:\n",
      "{}\n",
      "Full kwargs:\n",
      "{'_feature_generator_kwargs': None,\n",
      " '_save_bag_folds': None,\n",
      " 'ag_args': None,\n",
      " 'ag_args_ensemble': None,\n",
      " 'ag_args_fit': None,\n",
      " 'auto_stack': False,\n",
      " 'calibrate': 'auto',\n",
      " 'delay_bag_sets': False,\n",
      " 'ds_args': {'clean_up_fits': True,\n",
      "             'detection_time_frac': 0.25,\n",
      "             'enable_callbacks': False,\n",
      "             'enable_ray_logging': True,\n",
      "             'holdout_data': None,\n",
      "             'holdout_frac': 0.1111111111111111,\n",
      "             'memory_safe_fits': True,\n",
      "             'n_folds': 2,\n",
      "             'n_repeats': 1,\n",
      "             'validation_procedure': 'holdout'},\n",
      " 'excluded_model_types': None,\n",
      " 'feature_generator': 'auto',\n",
      " 'feature_prune_kwargs': None,\n",
      " 'holdout_frac': None,\n",
      " 'hyperparameter_tune_kwargs': None,\n",
      " 'included_model_types': None,\n",
      " 'keep_only_best': False,\n",
      " 'learning_curves': False,\n",
      " 'name_suffix': None,\n",
      " 'num_bag_folds': None,\n",
      " 'num_bag_sets': None,\n",
      " 'num_stack_levels': None,\n",
      " 'pseudo_data': None,\n",
      " 'raise_on_no_models_fitted': True,\n",
      " 'refit_full': False,\n",
      " 'save_bag_folds': None,\n",
      " 'save_space': False,\n",
      " 'set_best_to_refit_full': False,\n",
      " 'test_data': None,\n",
      " 'unlabeled_data': None,\n",
      " 'use_bag_holdout': False,\n",
      " 'verbosity': 3}\n",
      "========================================\n",
      "Saving /Users/patryk/test/kon/AutogluonModels/ag-20250308_144906/learner.pkl\n",
      "Saving /Users/patryk/test/kon/AutogluonModels/ag-20250308_144906/predictor.pkl\n",
      "Beginning AutoGluon training ... Time limit = 960s\n",
      "AutoGluon will save models to \"/Users/patryk/test/kon/AutogluonModels/ag-20250308_144906\"\n",
      "Train Data Rows:    166482\n",
      "Train Data Columns: 70\n",
      "Label Column:       sale price\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    6715.47 MB\n",
      "\tTrain Data (Original)  Memory Usage: 159.91 MB (2.4% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
      "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 46 | ['landuse', 'proxcode', 'bsmtcode', 'assessland', 'assesstot', ...]\n",
      "\t\t\t\t('int32', 'int')     :  5 | ['sale_year', 'sale_month', 'sale_day', 'sale_weekday', 'sale_quarter']\n",
      "\t\t\t\t('int64', 'int')     :  4 | ['borough', 'tax class at time of sale', 'buidling_class_num', 'changed_building_class']\n",
      "\t\t\t\t('object', 'object') : 13 | ['landmark', 'firecomp', 'sanitsub', 'zonedist1', 'zonedist2', ...]\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', [])  : 46 | ['landuse', 'proxcode', 'bsmtcode', 'assessland', 'assesstot', ...]\n",
      "\t\t\t\t('int', [])    :  9 | ['borough', 'tax class at time of sale', 'buidling_class_num', 'changed_building_class', 'sale_year', ...]\n",
      "\t\t\t\t('object', []) : 13 | ['landmark', 'firecomp', 'sanitsub', 'zonedist1', 'zonedist2', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', [])     : 44 | ['landuse', 'proxcode', 'bsmtcode', 'assessland', 'assesstot', ...]\n",
      "\t\t\t\t('int', [])       :  8 | ['borough', 'tax class at time of sale', 'buidling_class_num', 'sale_year', 'sale_month', ...]\n",
      "\t\t\t\t('int', ['bool']) :  4 | ['landmark', 'firm07_flag', 'pfirm15_flag', 'changed_building_class']\n",
      "\t\t\t\t('object', [])    : 12 | ['firecomp', 'sanitsub', 'zonedist1', 'zonedist2', 'overlay1', ...]\n",
      "\t\t\t0.1s = Fit runtime\n",
      "\t\t\t68 features in original data used to generate 68 features in processed data.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', [])     : 44 | ['landuse', 'proxcode', 'bsmtcode', 'assessland', 'assesstot', ...]\n",
      "\t\t\t\t('int', [])       :  8 | ['borough', 'tax class at time of sale', 'buidling_class_num', 'sale_year', 'sale_month', ...]\n",
      "\t\t\t\t('int', ['bool']) :  4 | ['landmark', 'firm07_flag', 'pfirm15_flag', 'changed_building_class']\n",
      "\t\t\t\t('object', [])    : 12 | ['firecomp', 'sanitsub', 'zonedist1', 'zonedist2', 'overlay1', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', [])     : 44 | ['landuse', 'proxcode', 'bsmtcode', 'assessland', 'assesstot', ...]\n",
      "\t\t\t\t('int', [])       :  8 | ['borough', 'tax class at time of sale', 'buidling_class_num', 'sale_year', 'sale_month', ...]\n",
      "\t\t\t\t('int', ['bool']) :  4 | ['landmark', 'firm07_flag', 'pfirm15_flag', 'changed_building_class']\n",
      "\t\t\t\t('object', [])    : 12 | ['firecomp', 'sanitsub', 'zonedist1', 'zonedist2', 'overlay1', ...]\n",
      "\t\t\t0.1s = Fit runtime\n",
      "\t\t\t68 features in original data used to generate 68 features in processed data.\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', [])     : 44 | ['landuse', 'proxcode', 'bsmtcode', 'assessland', 'assesstot', ...]\n",
      "\t\t\t\t('int', [])       :  8 | ['borough', 'tax class at time of sale', 'buidling_class_num', 'sale_year', 'sale_month', ...]\n",
      "\t\t\t\t('int', ['bool']) :  4 | ['landmark', 'firm07_flag', 'pfirm15_flag', 'changed_building_class']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', [])     : 44 | ['landuse', 'proxcode', 'bsmtcode', 'assessland', 'assesstot', ...]\n",
      "\t\t\t\t('int', [])       :  8 | ['borough', 'tax class at time of sale', 'buidling_class_num', 'sale_year', 'sale_month', ...]\n",
      "\t\t\t\t('int', ['bool']) :  4 | ['landmark', 'firm07_flag', 'pfirm15_flag', 'changed_building_class']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t56 features in original data used to generate 56 features in processed data.\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t\t('category', []) : 12 | ['firecomp', 'sanitsub', 'zonedist1', 'zonedist2', 'overlay1', ...]\n",
      "\t\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t\t('category', []) : 12 | ['firecomp', 'sanitsub', 'zonedist1', 'zonedist2', 'overlay1', ...]\n",
      "\t\t\t\t0.0s = Fit runtime\n",
      "\t\t\t\t12 features in original data used to generate 12 features in processed data.\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('object', []) : 12 | ['firecomp', 'sanitsub', 'zonedist1', 'zonedist2', 'overlay1', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('category', []) : 12 | ['firecomp', 'sanitsub', 'zonedist1', 'zonedist2', 'overlay1', ...]\n",
      "\t\t\t0.1s = Fit runtime\n",
      "\t\t\t12 features in original data used to generate 12 features in processed data.\n",
      "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('category', [])  : 12 | ['firecomp', 'sanitsub', 'zonedist1', 'zonedist2', 'overlay1', ...]\n",
      "\t\t\t\t('float', [])     : 44 | ['landuse', 'proxcode', 'bsmtcode', 'assessland', 'assesstot', ...]\n",
      "\t\t\t\t('int', [])       :  8 | ['borough', 'tax class at time of sale', 'buidling_class_num', 'sale_year', 'sale_month', ...]\n",
      "\t\t\t\t('int', ['bool']) :  4 | ['landmark', 'firm07_flag', 'pfirm15_flag', 'changed_building_class']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('category', [])  : 12 | ['firecomp', 'sanitsub', 'zonedist1', 'zonedist2', 'overlay1', ...]\n",
      "\t\t\t\t('float', [])     : 44 | ['landuse', 'proxcode', 'bsmtcode', 'assessland', 'assesstot', ...]\n",
      "\t\t\t\t('int', [])       :  8 | ['borough', 'tax class at time of sale', 'buidling_class_num', 'sale_year', 'sale_month', ...]\n",
      "\t\t\t\t('int', ['bool']) :  4 | ['landmark', 'firm07_flag', 'pfirm15_flag', 'changed_building_class']\n",
      "\t\t\t0.1s = Fit runtime\n",
      "\t\t\t68 features in original data used to generate 68 features in processed data.\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('category', [])  : 12 | ['firecomp', 'sanitsub', 'zonedist1', 'zonedist2', 'overlay1', ...]\n",
      "\t\t\t\t('float', [])     : 44 | ['landuse', 'proxcode', 'bsmtcode', 'assessland', 'assesstot', ...]\n",
      "\t\t\t\t('int', [])       :  8 | ['borough', 'tax class at time of sale', 'buidling_class_num', 'sale_year', 'sale_month', ...]\n",
      "\t\t\t\t('int', ['bool']) :  4 | ['landmark', 'firm07_flag', 'pfirm15_flag', 'changed_building_class']\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('category', [])  : 12 | ['firecomp', 'sanitsub', 'zonedist1', 'zonedist2', 'overlay1', ...]\n",
      "\t\t\t\t('float', [])     : 44 | ['landuse', 'proxcode', 'bsmtcode', 'assessland', 'assesstot', ...]\n",
      "\t\t\t\t('int', [])       :  8 | ['borough', 'tax class at time of sale', 'buidling_class_num', 'sale_year', 'sale_month', ...]\n",
      "\t\t\t\t('int', ['bool']) :  4 | ['landmark', 'firm07_flag', 'pfirm15_flag', 'changed_building_class']\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t68 features in original data used to generate 68 features in processed data.\n",
      "\tUseless Original Features (Count: 2): ['condono', 'spdist3']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 46 | ['landuse', 'proxcode', 'bsmtcode', 'assessland', 'assesstot', ...]\n",
      "\t\t('int32', 'int')     :  5 | ['sale_year', 'sale_month', 'sale_day', 'sale_weekday', 'sale_quarter']\n",
      "\t\t('int64', 'int')     :  4 | ['borough', 'tax class at time of sale', 'buidling_class_num', 'changed_building_class']\n",
      "\t\t('object', 'object') : 13 | ['landmark', 'firecomp', 'sanitsub', 'zonedist1', 'zonedist2', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 46 | ['landuse', 'proxcode', 'bsmtcode', 'assessland', 'assesstot', ...]\n",
      "\t\t('int', [])    :  9 | ['borough', 'tax class at time of sale', 'buidling_class_num', 'changed_building_class', 'sale_year', ...]\n",
      "\t\t('object', []) : 13 | ['landmark', 'firecomp', 'sanitsub', 'zonedist1', 'zonedist2', ...]\n",
      "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t('category', 'category') : 12 | ['firecomp', 'sanitsub', 'zonedist1', 'zonedist2', 'overlay1', ...]\n",
      "\t\t('float64', 'float')     : 44 | ['landuse', 'proxcode', 'bsmtcode', 'assessland', 'assesstot', ...]\n",
      "\t\t('int32', 'int')         :  5 | ['sale_year', 'sale_month', 'sale_day', 'sale_weekday', 'sale_quarter']\n",
      "\t\t('int64', 'int')         :  3 | ['borough', 'tax class at time of sale', 'buidling_class_num']\n",
      "\t\t('int8', 'int')          :  4 | ['landmark', 'firm07_flag', 'pfirm15_flag', 'changed_building_class']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 12 | ['firecomp', 'sanitsub', 'zonedist1', 'zonedist2', 'overlay1', ...]\n",
      "\t\t('float', [])     : 44 | ['landuse', 'proxcode', 'bsmtcode', 'assessland', 'assesstot', ...]\n",
      "\t\t('int', [])       :  8 | ['borough', 'tax class at time of sale', 'buidling_class_num', 'sale_year', 'sale_month', ...]\n",
      "\t\t('int', ['bool']) :  4 | ['landmark', 'firm07_flag', 'pfirm15_flag', 'changed_building_class']\n",
      "\t0.7s = Fit runtime\n",
      "\t68 features in original data used to generate 68 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 65.90 MB (1.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.79s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Saving /Users/patryk/test/kon/AutogluonModels/ag-20250308_144906/learner.pkl\n",
      "Automatically generating train/validation split with holdout_frac=0.015016638435386408, Train Rows: 163982, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Saving /Users/patryk/test/kon/AutogluonModels/ag-20250308_144906/utils/data/X.pkl\n",
      "Saving /Users/patryk/test/kon/AutogluonModels/ag-20250308_144906/utils/data/y.pkl\n",
      "Saving /Users/patryk/test/kon/AutogluonModels/ag-20250308_144906/utils/data/X_val.pkl\n",
      "Saving /Users/patryk/test/kon/AutogluonModels/ag-20250308_144906/utils/data/y_val.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tKNeighborsUnif: \t{'weights': 'uniform', 'ag_args': {'valid_stacker': False, 'problem_types': ['binary', 'multiclass', 'regression'], 'name_suffix': 'Unif', 'model_type': <class 'autogluon.tabular.models.knn.knn_model.KNNModel'>, 'priority': 100}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tKNeighborsDist: \t{'weights': 'distance', 'ag_args': {'valid_stacker': False, 'problem_types': ['binary', 'multiclass', 'regression'], 'name_suffix': 'Dist', 'model_type': <class 'autogluon.tabular.models.knn.knn_model.KNNModel'>, 'priority': 100}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tLightGBMXT: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tLightGBM: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tRandomForestMSE: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tCatBoost: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
      "\tExtraTreesMSE: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetFastAI: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
      "\tXGBoost: \t{'ag_args': {'problem_types': ['binary', 'multiclass', 'regression', 'softclass'], 'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
      "\tNeuralNetTorch: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "\tLightGBMLarge: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None, 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>}}\n",
      "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 959.21s of the 959.21s of remaining time.\n",
      "\tFitting KNeighborsUnif with 'num_gpus': 0, 'num_cpus': 11\n",
      "\t0.0s \t= Train Time (Using 10000/163982 rows) (959.14s remaining time)\n",
      "\t0.01s \t= Train Time (Using 20000/163982 rows) (959.14s remaining time)\n",
      "\t0.01s \t= Train Time (Using 40000/163982 rows) (959.13s remaining time)\n",
      "\t0.02s \t= Train Time (Using 80000/163982 rows) (959.11s remaining time)\n",
      "\t0.01s \t= Train Time (Using 163982/163982 rows) (959.1s remaining time)\n",
      "Saving /Users/patryk/test/kon/AutogluonModels/ag-20250308_144906/models/KNeighborsUnif/model.pkl\n",
      "Saving /Users/patryk/test/kon/AutogluonModels/ag-20250308_144906/utils/attr/KNeighborsUnif/y_pred_proba_val.pkl\n",
      "\t-301102.4056\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.11s\t = Training   runtime\n",
      "\t0.36s\t = Validation runtime\n",
      "\t6992.0\t = Inference  throughput (rows/s | 2500 batch size)\n",
      "Saving /Users/patryk/test/kon/AutogluonModels/ag-20250308_144906/models/trainer.pkl\n",
      "Fitting model: KNeighborsDist ... Training model for up to 958.67s of the 958.66s of remaining time.\n",
      "\tFitting KNeighborsDist with 'num_gpus': 0, 'num_cpus': 11\n",
      "\t0.01s \t= Train Time (Using 10000/163982 rows) (958.46s remaining time)\n",
      "\t0.01s \t= Train Time (Using 20000/163982 rows) (958.46s remaining time)\n",
      "\t0.01s \t= Train Time (Using 40000/163982 rows) (958.45s remaining time)\n",
      "\t0.02s \t= Train Time (Using 80000/163982 rows) (958.43s remaining time)\n",
      "\t0.01s \t= Train Time (Using 163982/163982 rows) (958.42s remaining time)\n",
      "Saving /Users/patryk/test/kon/AutogluonModels/ag-20250308_144906/models/KNeighborsDist/model.pkl\n",
      "Saving /Users/patryk/test/kon/AutogluonModels/ag-20250308_144906/utils/attr/KNeighborsDist/y_pred_proba_val.pkl\n",
      "\t-278155.6434\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.25s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "\t10622.5\t = Inference  throughput (rows/s | 2500 batch size)\n",
      "Saving /Users/patryk/test/kon/AutogluonModels/ag-20250308_144906/models/trainer.pkl\n",
      "Fitting model: LightGBMXT ... Training model for up to 958.17s of the 958.17s of remaining time.\n",
      "\tFitting LightGBMXT with 'num_gpus': 0, 'num_cpus': 11\n",
      "\tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05, 'extra_trees': True}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_set's rmse: 283422\n",
      "[100]\tvalid_set's rmse: 274477\n",
      "[150]\tvalid_set's rmse: 271301\n",
      "[200]\tvalid_set's rmse: 269475\n",
      "[250]\tvalid_set's rmse: 268338\n",
      "[300]\tvalid_set's rmse: 267381\n",
      "[350]\tvalid_set's rmse: 266478\n",
      "[400]\tvalid_set's rmse: 265725\n",
      "[450]\tvalid_set's rmse: 264999\n",
      "[500]\tvalid_set's rmse: 264401\n",
      "[550]\tvalid_set's rmse: 263826\n",
      "[600]\tvalid_set's rmse: 263442\n",
      "[650]\tvalid_set's rmse: 262884\n",
      "[700]\tvalid_set's rmse: 262617\n",
      "[750]\tvalid_set's rmse: 262340\n",
      "[800]\tvalid_set's rmse: 262207\n",
      "[850]\tvalid_set's rmse: 261635\n",
      "[900]\tvalid_set's rmse: 261419\n",
      "[950]\tvalid_set's rmse: 261273\n",
      "[1000]\tvalid_set's rmse: 261059\n",
      "[1050]\tvalid_set's rmse: 260725\n",
      "[1100]\tvalid_set's rmse: 260518\n",
      "[1150]\tvalid_set's rmse: 260435\n",
      "[1200]\tvalid_set's rmse: 260304\n",
      "[1250]\tvalid_set's rmse: 260139\n",
      "[1300]\tvalid_set's rmse: 260042\n",
      "[1350]\tvalid_set's rmse: 259956\n",
      "[1400]\tvalid_set's rmse: 259744\n",
      "[1450]\tvalid_set's rmse: 259580\n",
      "[1500]\tvalid_set's rmse: 259417\n",
      "[1550]\tvalid_set's rmse: 259195\n",
      "[1600]\tvalid_set's rmse: 259161\n",
      "[1650]\tvalid_set's rmse: 259061\n",
      "[1700]\tvalid_set's rmse: 258964\n",
      "[1750]\tvalid_set's rmse: 258824\n",
      "[1800]\tvalid_set's rmse: 258661\n",
      "[1850]\tvalid_set's rmse: 258378\n",
      "[1900]\tvalid_set's rmse: 258246\n",
      "[1950]\tvalid_set's rmse: 258214\n",
      "[2000]\tvalid_set's rmse: 258127\n",
      "[2050]\tvalid_set's rmse: 258107\n",
      "[2100]\tvalid_set's rmse: 258026\n",
      "[2150]\tvalid_set's rmse: 257915\n",
      "[2200]\tvalid_set's rmse: 257890\n",
      "[2250]\tvalid_set's rmse: 257968\n",
      "[2300]\tvalid_set's rmse: 257760\n",
      "[2350]\tvalid_set's rmse: 257666\n",
      "[2400]\tvalid_set's rmse: 257555\n",
      "[2450]\tvalid_set's rmse: 257482\n",
      "[2500]\tvalid_set's rmse: 257358\n",
      "[2550]\tvalid_set's rmse: 257306\n",
      "[2600]\tvalid_set's rmse: 257377\n",
      "[2650]\tvalid_set's rmse: 257307\n",
      "[2700]\tvalid_set's rmse: 257171\n",
      "[2750]\tvalid_set's rmse: 257057\n",
      "[2800]\tvalid_set's rmse: 257107\n",
      "[2850]\tvalid_set's rmse: 256983\n",
      "[2900]\tvalid_set's rmse: 256900\n",
      "[2950]\tvalid_set's rmse: 256896\n",
      "[3000]\tvalid_set's rmse: 256713\n",
      "[3050]\tvalid_set's rmse: 256628\n",
      "[3100]\tvalid_set's rmse: 256522\n",
      "[3150]\tvalid_set's rmse: 256501\n",
      "[3200]\tvalid_set's rmse: 256452\n",
      "[3250]\tvalid_set's rmse: 256442\n",
      "[3300]\tvalid_set's rmse: 256388\n",
      "[3350]\tvalid_set's rmse: 256237\n",
      "[3400]\tvalid_set's rmse: 256126\n",
      "[3450]\tvalid_set's rmse: 256112\n",
      "[3500]\tvalid_set's rmse: 256048\n",
      "[3550]\tvalid_set's rmse: 255974\n",
      "[3600]\tvalid_set's rmse: 255890\n",
      "[3650]\tvalid_set's rmse: 255908\n",
      "[3700]\tvalid_set's rmse: 255856\n",
      "[3750]\tvalid_set's rmse: 255795\n",
      "[3800]\tvalid_set's rmse: 255735\n",
      "[3850]\tvalid_set's rmse: 255721\n",
      "[3900]\tvalid_set's rmse: 255698\n",
      "[3950]\tvalid_set's rmse: 255630\n",
      "[4000]\tvalid_set's rmse: 255613\n",
      "[4050]\tvalid_set's rmse: 255564\n",
      "[4100]\tvalid_set's rmse: 255525\n",
      "[4150]\tvalid_set's rmse: 255468\n",
      "[4200]\tvalid_set's rmse: 255481\n",
      "[4250]\tvalid_set's rmse: 255408\n",
      "[4300]\tvalid_set's rmse: 255348\n",
      "[4350]\tvalid_set's rmse: 255332\n",
      "[4400]\tvalid_set's rmse: 255396\n",
      "[4450]\tvalid_set's rmse: 255373\n",
      "[4500]\tvalid_set's rmse: 255372\n",
      "[4550]\tvalid_set's rmse: 255382\n",
      "[4600]\tvalid_set's rmse: 255321\n",
      "[4650]\tvalid_set's rmse: 255366\n",
      "[4700]\tvalid_set's rmse: 255373\n",
      "[4750]\tvalid_set's rmse: 255274\n",
      "[4800]\tvalid_set's rmse: 255246\n",
      "[4850]\tvalid_set's rmse: 255270\n",
      "[4900]\tvalid_set's rmse: 255257\n",
      "[4950]\tvalid_set's rmse: 255220\n",
      "[5000]\tvalid_set's rmse: 255140\n",
      "[5050]\tvalid_set's rmse: 255114\n",
      "[5100]\tvalid_set's rmse: 255086\n",
      "[5150]\tvalid_set's rmse: 255106\n",
      "[5200]\tvalid_set's rmse: 255030\n",
      "[5250]\tvalid_set's rmse: 254996\n",
      "[5300]\tvalid_set's rmse: 254948\n",
      "[5350]\tvalid_set's rmse: 254900\n",
      "[5400]\tvalid_set's rmse: 255054\n",
      "[5450]\tvalid_set's rmse: 255046\n",
      "[5500]\tvalid_set's rmse: 255037\n",
      "[5550]\tvalid_set's rmse: 255061\n",
      "[5600]\tvalid_set's rmse: 255022\n",
      "[5650]\tvalid_set's rmse: 254966\n",
      "[5700]\tvalid_set's rmse: 254916\n",
      "[5750]\tvalid_set's rmse: 254819\n",
      "[5800]\tvalid_set's rmse: 254868\n",
      "[5850]\tvalid_set's rmse: 254861\n",
      "[5900]\tvalid_set's rmse: 254828\n",
      "[5950]\tvalid_set's rmse: 254791\n",
      "[6000]\tvalid_set's rmse: 254740\n",
      "[6050]\tvalid_set's rmse: 254643\n",
      "[6100]\tvalid_set's rmse: 254585\n",
      "[6150]\tvalid_set's rmse: 254623\n",
      "[6200]\tvalid_set's rmse: 254597\n",
      "[6250]\tvalid_set's rmse: 254566\n",
      "[6300]\tvalid_set's rmse: 254553\n",
      "[6350]\tvalid_set's rmse: 254608\n",
      "[6400]\tvalid_set's rmse: 254582\n",
      "[6450]\tvalid_set's rmse: 254607\n",
      "[6500]\tvalid_set's rmse: 254558\n",
      "[6550]\tvalid_set's rmse: 254644\n",
      "[6600]\tvalid_set's rmse: 254672\n",
      "[6650]\tvalid_set's rmse: 254600\n",
      "[6700]\tvalid_set's rmse: 254592\n",
      "[6750]\tvalid_set's rmse: 254580\n",
      "[6800]\tvalid_set's rmse: 254535\n",
      "[6850]\tvalid_set's rmse: 254468\n",
      "[6900]\tvalid_set's rmse: 254395\n",
      "[6950]\tvalid_set's rmse: 254386\n",
      "[7000]\tvalid_set's rmse: 254378\n",
      "[7050]\tvalid_set's rmse: 254353\n",
      "[7100]\tvalid_set's rmse: 254371\n",
      "[7150]\tvalid_set's rmse: 254281\n",
      "[7200]\tvalid_set's rmse: 254247\n",
      "[7250]\tvalid_set's rmse: 254210\n",
      "[7300]\tvalid_set's rmse: 254205\n",
      "[7350]\tvalid_set's rmse: 254225\n",
      "[7400]\tvalid_set's rmse: 254226\n",
      "[7450]\tvalid_set's rmse: 254291\n",
      "[7500]\tvalid_set's rmse: 254283\n",
      "[7550]\tvalid_set's rmse: 254221\n",
      "[7600]\tvalid_set's rmse: 254263\n",
      "[7650]\tvalid_set's rmse: 254268\n",
      "[7700]\tvalid_set's rmse: 254295\n",
      "[7750]\tvalid_set's rmse: 254307\n",
      "[7800]\tvalid_set's rmse: 254350\n",
      "[7850]\tvalid_set's rmse: 254350\n",
      "[7900]\tvalid_set's rmse: 254359\n",
      "[7950]\tvalid_set's rmse: 254384\n",
      "[8000]\tvalid_set's rmse: 254313\n",
      "[8050]\tvalid_set's rmse: 254260\n",
      "[8100]\tvalid_set's rmse: 254303\n",
      "[8150]\tvalid_set's rmse: 254289\n",
      "[8200]\tvalid_set's rmse: 254304\n",
      "[8250]\tvalid_set's rmse: 254223\n",
      "[8300]\tvalid_set's rmse: 254265\n",
      "[8350]\tvalid_set's rmse: 254251\n",
      "[8400]\tvalid_set's rmse: 254156\n",
      "[8450]\tvalid_set's rmse: 254113\n",
      "[8500]\tvalid_set's rmse: 254091\n",
      "[8550]\tvalid_set's rmse: 254033\n",
      "[8600]\tvalid_set's rmse: 253983\n",
      "[8650]\tvalid_set's rmse: 253979\n",
      "[8700]\tvalid_set's rmse: 253956\n",
      "[8750]\tvalid_set's rmse: 253954\n",
      "[8800]\tvalid_set's rmse: 253947\n",
      "[8850]\tvalid_set's rmse: 253949\n",
      "[8900]\tvalid_set's rmse: 253955\n",
      "[8950]\tvalid_set's rmse: 253982\n",
      "[9000]\tvalid_set's rmse: 254009\n",
      "[9050]\tvalid_set's rmse: 254005\n",
      "[9100]\tvalid_set's rmse: 254000\n",
      "[9150]\tvalid_set's rmse: 253989\n",
      "[9200]\tvalid_set's rmse: 253954\n",
      "[9250]\tvalid_set's rmse: 253914\n",
      "[9300]\tvalid_set's rmse: 253929\n",
      "[9350]\tvalid_set's rmse: 253906\n",
      "[9400]\tvalid_set's rmse: 253951\n",
      "[9450]\tvalid_set's rmse: 253878\n",
      "[9500]\tvalid_set's rmse: 253905\n",
      "[9550]\tvalid_set's rmse: 253812\n",
      "[9600]\tvalid_set's rmse: 253799\n",
      "[9650]\tvalid_set's rmse: 253799\n",
      "[9700]\tvalid_set's rmse: 253794\n",
      "[9750]\tvalid_set's rmse: 253740\n",
      "[9800]\tvalid_set's rmse: 253689\n",
      "[9850]\tvalid_set's rmse: 253693\n",
      "[9900]\tvalid_set's rmse: 253653\n",
      "[9950]\tvalid_set's rmse: 253666\n",
      "[10000]\tvalid_set's rmse: 253619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving /Users/patryk/test/kon/AutogluonModels/ag-20250308_144906/models/LightGBMXT/model.pkl\n",
      "Saving /Users/patryk/test/kon/AutogluonModels/ag-20250308_144906/utils/attr/LightGBMXT/y_pred_proba_val.pkl\n",
      "\t-253617.6293\t = Validation score   (-root_mean_squared_error)\n",
      "\t62.81s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "\t12555.9\t = Inference  throughput (rows/s | 2500 batch size)\n",
      "Saving /Users/patryk/test/kon/AutogluonModels/ag-20250308_144906/models/trainer.pkl\n",
      "Fitting model: LightGBM ... Training model for up to 895.00s of the 894.99s of remaining time.\n",
      "\tFitting LightGBM with 'num_gpus': 0, 'num_cpus': 11\n",
      "\tFitting 10000 rounds... Hyperparameters: {'learning_rate': 0.05}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\tvalid_set's rmse: 280794\n",
      "[100]\tvalid_set's rmse: 272510\n",
      "[150]\tvalid_set's rmse: 269430\n",
      "[200]\tvalid_set's rmse: 267562\n",
      "[250]\tvalid_set's rmse: 265861\n",
      "[300]\tvalid_set's rmse: 264487\n",
      "[350]\tvalid_set's rmse: 263354\n",
      "[400]\tvalid_set's rmse: 262774\n",
      "[450]\tvalid_set's rmse: 262123\n",
      "[500]\tvalid_set's rmse: 261647\n",
      "[550]\tvalid_set's rmse: 261066\n",
      "[600]\tvalid_set's rmse: 260559\n",
      "[650]\tvalid_set's rmse: 260106\n",
      "[700]\tvalid_set's rmse: 259498\n",
      "[750]\tvalid_set's rmse: 258893\n",
      "[800]\tvalid_set's rmse: 258699\n",
      "[850]\tvalid_set's rmse: 258263\n",
      "[900]\tvalid_set's rmse: 258341\n",
      "[950]\tvalid_set's rmse: 257937\n",
      "[1000]\tvalid_set's rmse: 257421\n",
      "[1050]\tvalid_set's rmse: 257102\n",
      "[1100]\tvalid_set's rmse: 256746\n",
      "[1150]\tvalid_set's rmse: 256474\n",
      "[1200]\tvalid_set's rmse: 256251\n",
      "[1250]\tvalid_set's rmse: 256107\n",
      "[1300]\tvalid_set's rmse: 255652\n",
      "[1350]\tvalid_set's rmse: 255324\n",
      "[1400]\tvalid_set's rmse: 255091\n",
      "[1450]\tvalid_set's rmse: 254967\n",
      "[1500]\tvalid_set's rmse: 254907\n",
      "[1550]\tvalid_set's rmse: 254651\n",
      "[1600]\tvalid_set's rmse: 254482\n",
      "[1650]\tvalid_set's rmse: 254309\n",
      "[1700]\tvalid_set's rmse: 254099\n",
      "[1750]\tvalid_set's rmse: 253976\n",
      "[1800]\tvalid_set's rmse: 253774\n",
      "[1850]\tvalid_set's rmse: 253645\n",
      "[1900]\tvalid_set's rmse: 253606\n",
      "[1950]\tvalid_set's rmse: 253359\n",
      "[2000]\tvalid_set's rmse: 253320\n",
      "[2050]\tvalid_set's rmse: 253058\n",
      "[2100]\tvalid_set's rmse: 253074\n",
      "[2150]\tvalid_set's rmse: 253047\n",
      "[2200]\tvalid_set's rmse: 252953\n",
      "[2250]\tvalid_set's rmse: 252884\n",
      "[2300]\tvalid_set's rmse: 252661\n",
      "[2350]\tvalid_set's rmse: 252510\n",
      "[2400]\tvalid_set's rmse: 252295\n",
      "[2450]\tvalid_set's rmse: 252020\n",
      "[2500]\tvalid_set's rmse: 251852\n",
      "[2550]\tvalid_set's rmse: 251683\n",
      "[2600]\tvalid_set's rmse: 251556\n",
      "[2650]\tvalid_set's rmse: 251512\n",
      "[2700]\tvalid_set's rmse: 251448\n",
      "[2750]\tvalid_set's rmse: 251421\n",
      "[2800]\tvalid_set's rmse: 251409\n",
      "[2850]\tvalid_set's rmse: 251292\n",
      "[2900]\tvalid_set's rmse: 251150\n",
      "[2950]\tvalid_set's rmse: 251032\n",
      "[3000]\tvalid_set's rmse: 250839\n",
      "[3050]\tvalid_set's rmse: 250652\n",
      "[3100]\tvalid_set's rmse: 250618\n",
      "[3150]\tvalid_set's rmse: 250716\n",
      "[3200]\tvalid_set's rmse: 250636\n",
      "[3250]\tvalid_set's rmse: 250667\n",
      "[3300]\tvalid_set's rmse: 250495\n",
      "[3350]\tvalid_set's rmse: 250463\n",
      "[3400]\tvalid_set's rmse: 250362\n",
      "[3450]\tvalid_set's rmse: 250373\n",
      "[3500]\tvalid_set's rmse: 250345\n",
      "[3550]\tvalid_set's rmse: 250249\n",
      "[3600]\tvalid_set's rmse: 250204\n",
      "[3650]\tvalid_set's rmse: 250258\n",
      "[3700]\tvalid_set's rmse: 250236\n",
      "[3750]\tvalid_set's rmse: 250109\n",
      "[3800]\tvalid_set's rmse: 250081\n",
      "[3850]\tvalid_set's rmse: 250158\n",
      "[3900]\tvalid_set's rmse: 250148\n",
      "[3950]\tvalid_set's rmse: 250206\n",
      "[4000]\tvalid_set's rmse: 250118\n",
      "[4050]\tvalid_set's rmse: 250100\n",
      "[4100]\tvalid_set's rmse: 250098\n",
      "[4150]\tvalid_set's rmse: 250168\n",
      "[4200]\tvalid_set's rmse: 250083\n",
      "[4250]\tvalid_set's rmse: 250003\n",
      "[4300]\tvalid_set's rmse: 249902\n",
      "[4350]\tvalid_set's rmse: 249888\n",
      "[4400]\tvalid_set's rmse: 249840\n",
      "[4450]\tvalid_set's rmse: 249730\n",
      "[4500]\tvalid_set's rmse: 249756\n",
      "[4550]\tvalid_set's rmse: 249713\n",
      "[4600]\tvalid_set's rmse: 249636\n",
      "[4650]\tvalid_set's rmse: 249589\n",
      "[4700]\tvalid_set's rmse: 249533\n",
      "[4750]\tvalid_set's rmse: 249543\n",
      "[4800]\tvalid_set's rmse: 249617\n",
      "[4850]\tvalid_set's rmse: 249623\n",
      "[4900]\tvalid_set's rmse: 249680\n",
      "[4950]\tvalid_set's rmse: 249592\n",
      "[5000]\tvalid_set's rmse: 249513\n",
      "[5050]\tvalid_set's rmse: 249469\n",
      "[5100]\tvalid_set's rmse: 249464\n",
      "[5150]\tvalid_set's rmse: 249440\n",
      "[5200]\tvalid_set's rmse: 249454\n",
      "[5250]\tvalid_set's rmse: 249436\n",
      "[5300]\tvalid_set's rmse: 249322\n",
      "[5350]\tvalid_set's rmse: 249325\n",
      "[5400]\tvalid_set's rmse: 249245\n",
      "[5450]\tvalid_set's rmse: 249080\n",
      "[5500]\tvalid_set's rmse: 249070\n",
      "[5550]\tvalid_set's rmse: 249025\n",
      "[5600]\tvalid_set's rmse: 249059\n",
      "[5650]\tvalid_set's rmse: 248957\n",
      "[5700]\tvalid_set's rmse: 248982\n",
      "[5750]\tvalid_set's rmse: 248971\n",
      "[5800]\tvalid_set's rmse: 249009\n",
      "[5850]\tvalid_set's rmse: 249190\n",
      "[5900]\tvalid_set's rmse: 249270\n",
      "[5950]\tvalid_set's rmse: 249221\n",
      "[6000]\tvalid_set's rmse: 249252\n",
      "[6050]\tvalid_set's rmse: 249218\n",
      "[6100]\tvalid_set's rmse: 249251\n",
      "[6150]\tvalid_set's rmse: 249202\n",
      "[6200]\tvalid_set's rmse: 249174\n",
      "[6250]\tvalid_set's rmse: 249191\n",
      "[6300]\tvalid_set's rmse: 249151\n",
      "[6350]\tvalid_set's rmse: 249194\n",
      "[6400]\tvalid_set's rmse: 249116\n",
      "[6450]\tvalid_set's rmse: 249024\n",
      "[6500]\tvalid_set's rmse: 248947\n",
      "[6550]\tvalid_set's rmse: 248954\n",
      "[6600]\tvalid_set's rmse: 248952\n",
      "[6650]\tvalid_set's rmse: 248912\n",
      "[6700]\tvalid_set's rmse: 248968\n",
      "[6750]\tvalid_set's rmse: 248847\n",
      "[6800]\tvalid_set's rmse: 248836\n",
      "[6850]\tvalid_set's rmse: 248791\n",
      "[6900]\tvalid_set's rmse: 248809\n",
      "[6950]\tvalid_set's rmse: 248760\n",
      "[7000]\tvalid_set's rmse: 248718\n",
      "[7050]\tvalid_set's rmse: 248726\n",
      "[7100]\tvalid_set's rmse: 248669\n",
      "[7150]\tvalid_set's rmse: 248608\n",
      "[7200]\tvalid_set's rmse: 248604\n",
      "[7250]\tvalid_set's rmse: 248582\n",
      "[7300]\tvalid_set's rmse: 248578\n",
      "[7350]\tvalid_set's rmse: 248603\n",
      "[7400]\tvalid_set's rmse: 248560\n",
      "[7450]\tvalid_set's rmse: 248533\n",
      "[7500]\tvalid_set's rmse: 248536\n",
      "[7550]\tvalid_set's rmse: 248585\n",
      "[7600]\tvalid_set's rmse: 248514\n",
      "[7650]\tvalid_set's rmse: 248610\n",
      "[7700]\tvalid_set's rmse: 248590\n",
      "[7750]\tvalid_set's rmse: 248604\n",
      "[7800]\tvalid_set's rmse: 248449\n",
      "[7850]\tvalid_set's rmse: 248359\n",
      "[7900]\tvalid_set's rmse: 248227\n",
      "[7950]\tvalid_set's rmse: 248154\n",
      "[8000]\tvalid_set's rmse: 248169\n",
      "[8050]\tvalid_set's rmse: 248169\n",
      "[8100]\tvalid_set's rmse: 248152\n",
      "[8150]\tvalid_set's rmse: 248160\n",
      "[8200]\tvalid_set's rmse: 248134\n",
      "[8250]\tvalid_set's rmse: 248102\n",
      "[8300]\tvalid_set's rmse: 248137\n",
      "[8350]\tvalid_set's rmse: 248172\n",
      "[8400]\tvalid_set's rmse: 248126\n",
      "[8450]\tvalid_set's rmse: 248131\n",
      "[8500]\tvalid_set's rmse: 248144\n",
      "[8550]\tvalid_set's rmse: 248111\n",
      "[8600]\tvalid_set's rmse: 248069\n",
      "[8650]\tvalid_set's rmse: 248072\n",
      "[8700]\tvalid_set's rmse: 248067\n",
      "[8750]\tvalid_set's rmse: 248107\n",
      "[8800]\tvalid_set's rmse: 248054\n",
      "[8850]\tvalid_set's rmse: 248032\n",
      "[8900]\tvalid_set's rmse: 248070\n",
      "[8950]\tvalid_set's rmse: 248088\n",
      "[9000]\tvalid_set's rmse: 248053\n",
      "[9050]\tvalid_set's rmse: 248049\n",
      "[9100]\tvalid_set's rmse: 248070\n",
      "[9150]\tvalid_set's rmse: 248107\n",
      "[9200]\tvalid_set's rmse: 248146\n",
      "[9250]\tvalid_set's rmse: 248104\n",
      "[9300]\tvalid_set's rmse: 248139\n",
      "[9350]\tvalid_set's rmse: 248116\n",
      "[9400]\tvalid_set's rmse: 248151\n",
      "[9450]\tvalid_set's rmse: 248182\n",
      "[9500]\tvalid_set's rmse: 248144\n",
      "[9550]\tvalid_set's rmse: 248088\n",
      "[9600]\tvalid_set's rmse: 248061\n",
      "[9650]\tvalid_set's rmse: 248075\n",
      "[9700]\tvalid_set's rmse: 248071\n",
      "[9750]\tvalid_set's rmse: 248072\n",
      "[9800]\tvalid_set's rmse: 248085\n",
      "[9850]\tvalid_set's rmse: 248076\n",
      "[9900]\tvalid_set's rmse: 248027\n",
      "[9950]\tvalid_set's rmse: 248047\n",
      "[10000]\tvalid_set's rmse: 248072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving /Users/patryk/test/kon/AutogluonModels/ag-20250308_144906/models/LightGBM/model.pkl\n",
      "Saving /Users/patryk/test/kon/AutogluonModels/ag-20250308_144906/utils/attr/LightGBM/y_pred_proba_val.pkl\n",
      "\t-247997.1531\t = Validation score   (-root_mean_squared_error)\n",
      "\t59.89s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "\t17607.7\t = Inference  throughput (rows/s | 2500 batch size)\n",
      "Saving /Users/patryk/test/kon/AutogluonModels/ag-20250308_144906/models/trainer.pkl\n",
      "Fitting model: RandomForestMSE ... Training model for up to 834.81s of the 834.81s of remaining time.\n",
      "\tFitting RandomForestMSE with 'num_gpus': 0, 'num_cpus': 11\n",
      "Saving /Users/patryk/test/kon/AutogluonModels/ag-20250308_144906/models/RandomForestMSE/model.pkl\n",
      "Saving /Users/patryk/test/kon/AutogluonModels/ag-20250308_144906/utils/attr/RandomForestMSE/y_pred_proba_val.pkl\n",
      "\t-239098.6527\t = Validation score   (-root_mean_squared_error)\n",
      "\t96.29s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "\t44805.4\t = Inference  throughput (rows/s | 2500 batch size)\n",
      "Saving /Users/patryk/test/kon/AutogluonModels/ag-20250308_144906/models/trainer.pkl\n",
      "Fitting model: CatBoost ... Training model for up to 738.20s of the 738.20s of remaining time.\n",
      "\tFitting CatBoost with 'num_gpus': 0, 'num_cpus': 11\n",
      "\tCatboost model hyperparameters: {'iterations': 10000, 'learning_rate': 0.05, 'random_seed': 0, 'allow_writing_files': False, 'eval_metric': 'RMSE', 'thread_count': 11}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 386646.3057467\ttest: 390387.5728132\tbest: 390387.5728132 (0)\ttotal: 113ms\tremaining: 18m 49s\n",
      "20:\tlearn: 313087.6091011\ttest: 318005.5371723\tbest: 318005.5371723 (20)\ttotal: 912ms\tremaining: 7m 13s\n",
      "40:\tlearn: 292482.8235324\ttest: 297767.2112169\tbest: 297767.2112169 (40)\ttotal: 1.54s\tremaining: 6m 13s\n",
      "60:\tlearn: 285036.3405085\ttest: 291078.0768987\tbest: 291078.0768987 (60)\ttotal: 2.34s\tremaining: 6m 20s\n",
      "80:\tlearn: 281597.3151635\ttest: 287965.1528745\tbest: 287965.1528745 (80)\ttotal: 3.26s\tremaining: 6m 39s\n",
      "100:\tlearn: 279006.4401101\ttest: 285604.5170167\tbest: 285604.5170167 (100)\ttotal: 4.08s\tremaining: 6m 40s\n",
      "120:\tlearn: 277042.0591235\ttest: 284029.8757703\tbest: 284029.8757703 (120)\ttotal: 4.88s\tremaining: 6m 38s\n",
      "140:\tlearn: 275503.3527634\ttest: 282634.0167921\tbest: 282634.0167921 (140)\ttotal: 5.68s\tremaining: 6m 37s\n",
      "160:\tlearn: 274118.9310948\ttest: 281528.9934838\tbest: 281528.9934838 (160)\ttotal: 6.49s\tremaining: 6m 36s\n",
      "180:\tlearn: 272925.5126673\ttest: 280465.4805776\tbest: 280465.4805776 (180)\ttotal: 7.28s\tremaining: 6m 34s\n",
      "200:\tlearn: 271742.4517953\ttest: 279508.5425113\tbest: 279508.5425113 (200)\ttotal: 8.02s\tremaining: 6m 30s\n",
      "220:\tlearn: 270789.2281823\ttest: 278613.8393882\tbest: 278613.8393882 (220)\ttotal: 8.79s\tremaining: 6m 28s\n",
      "240:\tlearn: 269921.6430407\ttest: 277784.5702144\tbest: 277784.5702144 (240)\ttotal: 9.59s\tremaining: 6m 28s\n",
      "260:\tlearn: 269076.9005948\ttest: 277196.3570226\tbest: 277189.9889566 (259)\ttotal: 10.4s\tremaining: 6m 29s\n",
      "280:\tlearn: 268224.2452498\ttest: 276702.2208676\tbest: 276702.2208676 (280)\ttotal: 11.2s\tremaining: 6m 28s\n",
      "300:\tlearn: 267305.6620391\ttest: 276064.1425432\tbest: 276064.1425432 (300)\ttotal: 12.1s\tremaining: 6m 28s\n",
      "320:\tlearn: 266648.1124697\ttest: 275636.1873391\tbest: 275631.3666398 (319)\ttotal: 12.9s\tremaining: 6m 29s\n",
      "340:\tlearn: 265956.8514046\ttest: 275030.2483261\tbest: 275030.2483261 (340)\ttotal: 13.8s\tremaining: 6m 29s\n",
      "360:\tlearn: 265385.0636655\ttest: 274584.8299130\tbest: 274584.8299130 (360)\ttotal: 14.6s\tremaining: 6m 29s\n",
      "380:\tlearn: 264789.9669342\ttest: 274277.5495262\tbest: 274277.5495262 (380)\ttotal: 15.4s\tremaining: 6m 28s\n",
      "400:\tlearn: 264255.8000680\ttest: 273894.1869132\tbest: 273894.1869132 (400)\ttotal: 16.2s\tremaining: 6m 28s\n",
      "420:\tlearn: 263726.9451642\ttest: 273553.7534873\tbest: 273553.7534873 (420)\ttotal: 17s\tremaining: 6m 27s\n",
      "440:\tlearn: 263126.6396249\ttest: 273189.3802329\tbest: 273189.3802329 (440)\ttotal: 17.9s\tremaining: 6m 27s\n",
      "460:\tlearn: 262764.8032428\ttest: 273092.9093290\tbest: 273074.6538534 (456)\ttotal: 18.7s\tremaining: 6m 25s\n",
      "480:\tlearn: 262268.5109020\ttest: 272734.1092428\tbest: 272721.5045109 (479)\ttotal: 19.5s\tremaining: 6m 26s\n",
      "500:\tlearn: 261770.2396852\ttest: 272398.0640661\tbest: 272398.0640661 (500)\ttotal: 20.3s\tremaining: 6m 25s\n",
      "520:\tlearn: 261346.9359075\ttest: 272176.5168671\tbest: 272176.5168671 (520)\ttotal: 21.1s\tremaining: 6m 24s\n",
      "540:\tlearn: 260939.4208450\ttest: 271885.4882292\tbest: 271885.4882292 (540)\ttotal: 22s\tremaining: 6m 25s\n",
      "560:\tlearn: 260575.9787903\ttest: 271621.4039722\tbest: 271621.4039722 (560)\ttotal: 23s\tremaining: 6m 27s\n",
      "580:\tlearn: 260122.3103249\ttest: 271300.1548770\tbest: 271300.1548770 (580)\ttotal: 23.9s\tremaining: 6m 28s\n",
      "600:\tlearn: 259834.0060543\ttest: 271117.5040416\tbest: 271112.8438775 (599)\ttotal: 24.9s\tremaining: 6m 29s\n",
      "620:\tlearn: 259482.8154790\ttest: 270788.2094354\tbest: 270788.2094354 (620)\ttotal: 25.8s\tremaining: 6m 29s\n",
      "640:\tlearn: 259188.8581783\ttest: 270532.5046880\tbest: 270532.1962115 (639)\ttotal: 26.6s\tremaining: 6m 28s\n",
      "660:\tlearn: 258847.1418948\ttest: 270286.9167033\tbest: 270286.9167033 (660)\ttotal: 27.5s\tremaining: 6m 27s\n",
      "680:\tlearn: 258491.5004421\ttest: 270108.8743385\tbest: 270108.8743385 (680)\ttotal: 28.3s\tremaining: 6m 26s\n",
      "700:\tlearn: 258088.5509483\ttest: 269849.3698667\tbest: 269849.3698667 (700)\ttotal: 29.2s\tremaining: 6m 27s\n",
      "720:\tlearn: 257780.7737150\ttest: 269726.5632979\tbest: 269722.9558140 (719)\ttotal: 30s\tremaining: 6m 26s\n",
      "740:\tlearn: 257481.2431228\ttest: 269570.4261720\tbest: 269566.9600927 (738)\ttotal: 30.8s\tremaining: 6m 24s\n",
      "760:\tlearn: 257207.5241624\ttest: 269384.9943254\tbest: 269380.1004764 (759)\ttotal: 31.6s\tremaining: 6m 23s\n",
      "780:\tlearn: 256913.0611767\ttest: 269265.4639027\tbest: 269265.4639027 (780)\ttotal: 32.4s\tremaining: 6m 22s\n",
      "800:\tlearn: 256622.4776028\ttest: 269096.8551983\tbest: 269096.8551983 (800)\ttotal: 33.2s\tremaining: 6m 21s\n",
      "820:\tlearn: 256348.5589841\ttest: 269060.4789207\tbest: 269052.8835977 (819)\ttotal: 34s\tremaining: 6m 19s\n",
      "840:\tlearn: 256061.0283036\ttest: 268922.2931497\tbest: 268922.2931497 (840)\ttotal: 34.8s\tremaining: 6m 18s\n",
      "860:\tlearn: 255850.6641286\ttest: 268893.3961585\tbest: 268892.0712585 (851)\ttotal: 35.6s\tremaining: 6m 17s\n",
      "880:\tlearn: 255514.3756160\ttest: 268651.1700646\tbest: 268651.1700646 (880)\ttotal: 36.4s\tremaining: 6m 17s\n",
      "900:\tlearn: 255211.9512461\ttest: 268469.2951201\tbest: 268467.9601668 (899)\ttotal: 37.3s\tremaining: 6m 16s\n",
      "920:\tlearn: 254899.5375368\ttest: 268296.6060829\tbest: 268296.6060829 (920)\ttotal: 38.2s\tremaining: 6m 16s\n",
      "940:\tlearn: 254662.8206318\ttest: 268179.5655376\tbest: 268172.3504545 (935)\ttotal: 39.1s\tremaining: 6m 16s\n",
      "960:\tlearn: 254367.5600345\ttest: 267899.8223366\tbest: 267899.8223366 (960)\ttotal: 39.9s\tremaining: 6m 15s\n",
      "980:\tlearn: 254164.4086409\ttest: 267872.5816995\tbest: 267872.5816995 (980)\ttotal: 40.7s\tremaining: 6m 14s\n",
      "1000:\tlearn: 253956.1933580\ttest: 267847.2697212\tbest: 267843.8734060 (992)\ttotal: 41.5s\tremaining: 6m 13s\n",
      "1020:\tlearn: 253668.7967407\ttest: 267664.8145895\tbest: 267664.8145895 (1020)\ttotal: 42.3s\tremaining: 6m 12s\n",
      "1040:\tlearn: 253412.9185991\ttest: 267420.6842138\tbest: 267420.6842138 (1040)\ttotal: 43.2s\tremaining: 6m 11s\n",
      "1060:\tlearn: 253177.7516273\ttest: 267353.8782545\tbest: 267353.8354874 (1059)\ttotal: 44s\tremaining: 6m 10s\n",
      "1080:\tlearn: 252984.8074482\ttest: 267317.3963885\tbest: 267317.3963885 (1080)\ttotal: 45s\tremaining: 6m 11s\n",
      "1100:\tlearn: 252764.8826589\ttest: 267137.0166580\tbest: 267137.0166580 (1100)\ttotal: 45.8s\tremaining: 6m 10s\n",
      "1120:\tlearn: 252571.0323397\ttest: 267029.0432154\tbest: 267029.0432154 (1120)\ttotal: 46.6s\tremaining: 6m 9s\n",
      "1140:\tlearn: 252368.8184534\ttest: 266940.7115219\tbest: 266940.7115219 (1140)\ttotal: 47.4s\tremaining: 6m 8s\n",
      "1160:\tlearn: 252138.9814770\ttest: 266846.9189610\tbest: 266846.9189610 (1160)\ttotal: 48.2s\tremaining: 6m 7s\n",
      "1180:\tlearn: 251981.7717358\ttest: 266766.3848223\tbest: 266757.5377913 (1174)\ttotal: 49.1s\tremaining: 6m 6s\n",
      "1200:\tlearn: 251783.6896131\ttest: 266699.6243519\tbest: 266684.8548240 (1196)\ttotal: 50s\tremaining: 6m 6s\n",
      "1220:\tlearn: 251568.7028284\ttest: 266605.5660675\tbest: 266605.5660675 (1220)\ttotal: 51s\tremaining: 6m 6s\n",
      "1240:\tlearn: 251357.8528799\ttest: 266451.9694337\tbest: 266451.9694337 (1240)\ttotal: 51.9s\tremaining: 6m 6s\n",
      "1260:\tlearn: 251184.4225940\ttest: 266312.7151442\tbest: 266312.7151442 (1260)\ttotal: 52.8s\tremaining: 6m 5s\n",
      "1280:\tlearn: 250961.6768788\ttest: 266233.9778124\tbest: 266233.9778124 (1280)\ttotal: 53.6s\tremaining: 6m 4s\n",
      "1300:\tlearn: 250776.2553037\ttest: 266185.4717562\tbest: 266185.4717562 (1300)\ttotal: 54.4s\tremaining: 6m 3s\n",
      "1320:\tlearn: 250567.0721494\ttest: 266062.9350637\tbest: 266062.9350637 (1320)\ttotal: 55.3s\tremaining: 6m 3s\n",
      "1340:\tlearn: 250359.6118870\ttest: 265918.1899977\tbest: 265918.1899977 (1340)\ttotal: 56.2s\tremaining: 6m 2s\n",
      "1360:\tlearn: 250157.7688748\ttest: 265870.2331492\tbest: 265860.1679526 (1350)\ttotal: 57s\tremaining: 6m 1s\n",
      "1380:\tlearn: 249977.2497310\ttest: 265802.7950215\tbest: 265802.7950215 (1380)\ttotal: 57.8s\tremaining: 6m\n",
      "1400:\tlearn: 249806.0833754\ttest: 265772.4998420\tbest: 265756.7559039 (1399)\ttotal: 58.6s\tremaining: 5m 59s\n",
      "1420:\tlearn: 249641.7954768\ttest: 265705.7353647\tbest: 265703.8426438 (1417)\ttotal: 59.5s\tremaining: 5m 58s\n",
      "1440:\tlearn: 249490.3576028\ttest: 265673.8868715\tbest: 265669.4679579 (1429)\ttotal: 1m\tremaining: 5m 57s\n",
      "1460:\tlearn: 249306.6076590\ttest: 265642.9432819\tbest: 265622.3986713 (1447)\ttotal: 1m 1s\tremaining: 5m 57s\n",
      "1480:\tlearn: 249100.1045128\ttest: 265472.9367472\tbest: 265472.9367472 (1480)\ttotal: 1m 1s\tremaining: 5m 55s\n",
      "1500:\tlearn: 248891.8402315\ttest: 265254.9428353\tbest: 265254.9428353 (1500)\ttotal: 1m 2s\tremaining: 5m 54s\n",
      "1520:\tlearn: 248697.1542566\ttest: 265188.8324974\tbest: 265188.8324974 (1520)\ttotal: 1m 3s\tremaining: 5m 53s\n",
      "1540:\tlearn: 248485.2420189\ttest: 265098.3090850\tbest: 265098.3090850 (1540)\ttotal: 1m 4s\tremaining: 5m 52s\n",
      "1560:\tlearn: 248316.5775284\ttest: 265067.7448104\tbest: 265067.7448104 (1560)\ttotal: 1m 5s\tremaining: 5m 52s\n",
      "1580:\tlearn: 248160.9971291\ttest: 265066.5602384\tbest: 265030.9570869 (1567)\ttotal: 1m 5s\tremaining: 5m 51s\n",
      "1600:\tlearn: 247999.6431725\ttest: 264953.6163363\tbest: 264952.8847667 (1599)\ttotal: 1m 6s\tremaining: 5m 50s\n",
      "1620:\tlearn: 247781.6143630\ttest: 264820.2274429\tbest: 264807.4146574 (1618)\ttotal: 1m 7s\tremaining: 5m 49s\n",
      "1640:\tlearn: 247618.1302014\ttest: 264749.4810590\tbest: 264749.4810590 (1640)\ttotal: 1m 8s\tremaining: 5m 48s\n",
      "1660:\tlearn: 247463.6929948\ttest: 264636.2888751\tbest: 264636.2888751 (1660)\ttotal: 1m 9s\tremaining: 5m 48s\n",
      "1680:\tlearn: 247307.8919914\ttest: 264581.2172540\tbest: 264581.2172540 (1680)\ttotal: 1m 10s\tremaining: 5m 47s\n",
      "1700:\tlearn: 247118.4563307\ttest: 264506.8674320\tbest: 264506.3126612 (1695)\ttotal: 1m 11s\tremaining: 5m 46s\n",
      "1720:\tlearn: 246950.7896968\ttest: 264491.0950650\tbest: 264478.4848782 (1715)\ttotal: 1m 11s\tremaining: 5m 45s\n",
      "1740:\tlearn: 246791.0478529\ttest: 264400.1999867\tbest: 264398.0314551 (1739)\ttotal: 1m 12s\tremaining: 5m 44s\n",
      "1760:\tlearn: 246638.2912956\ttest: 264364.0669473\tbest: 264361.9561384 (1759)\ttotal: 1m 13s\tremaining: 5m 44s\n",
      "1780:\tlearn: 246450.2935485\ttest: 264370.1360196\tbest: 264346.5433632 (1768)\ttotal: 1m 14s\tremaining: 5m 43s\n",
      "1800:\tlearn: 246289.6721567\ttest: 264323.5082915\tbest: 264323.5082915 (1800)\ttotal: 1m 15s\tremaining: 5m 42s\n",
      "1820:\tlearn: 246146.2288356\ttest: 264247.6445253\tbest: 264247.0705812 (1814)\ttotal: 1m 16s\tremaining: 5m 41s\n",
      "1840:\tlearn: 245995.8541840\ttest: 264182.8306367\tbest: 264182.8306367 (1840)\ttotal: 1m 16s\tremaining: 5m 40s\n",
      "1860:\tlearn: 245844.4596042\ttest: 264119.1470668\tbest: 264118.9738525 (1859)\ttotal: 1m 17s\tremaining: 5m 39s\n",
      "1880:\tlearn: 245696.1325011\ttest: 264077.6471463\tbest: 264077.6471463 (1880)\ttotal: 1m 18s\tremaining: 5m 38s\n",
      "1900:\tlearn: 245534.0904262\ttest: 264022.4403869\tbest: 264022.4403869 (1900)\ttotal: 1m 19s\tremaining: 5m 37s\n",
      "1920:\tlearn: 245375.2660971\ttest: 264017.0818405\tbest: 264004.9737352 (1918)\ttotal: 1m 20s\tremaining: 5m 36s\n",
      "1940:\tlearn: 245202.1617702\ttest: 263974.6470469\tbest: 263974.6470469 (1940)\ttotal: 1m 20s\tremaining: 5m 35s\n",
      "1960:\tlearn: 245050.5737627\ttest: 263846.4764041\tbest: 263846.4764041 (1960)\ttotal: 1m 21s\tremaining: 5m 34s\n",
      "1980:\tlearn: 244912.4146909\ttest: 263810.5638941\tbest: 263784.2038950 (1976)\ttotal: 1m 22s\tremaining: 5m 34s\n",
      "2000:\tlearn: 244763.4907683\ttest: 263705.6645050\tbest: 263705.6645050 (2000)\ttotal: 1m 23s\tremaining: 5m 33s\n",
      "2020:\tlearn: 244639.9028933\ttest: 263714.2305673\tbest: 263693.6204130 (2006)\ttotal: 1m 24s\tremaining: 5m 32s\n",
      "2040:\tlearn: 244513.0682774\ttest: 263678.4658442\tbest: 263678.4658442 (2040)\ttotal: 1m 24s\tremaining: 5m 31s\n",
      "2060:\tlearn: 244357.4589205\ttest: 263617.7036200\tbest: 263592.6182220 (2057)\ttotal: 1m 25s\tremaining: 5m 30s\n",
      "2080:\tlearn: 244240.5347062\ttest: 263587.6025914\tbest: 263587.6025914 (2080)\ttotal: 1m 26s\tremaining: 5m 29s\n",
      "2100:\tlearn: 244076.3469274\ttest: 263546.8142267\tbest: 263546.0915663 (2090)\ttotal: 1m 27s\tremaining: 5m 28s\n",
      "2120:\tlearn: 243942.3079748\ttest: 263501.7251492\tbest: 263500.5982486 (2111)\ttotal: 1m 28s\tremaining: 5m 28s\n",
      "2140:\tlearn: 243796.2925662\ttest: 263468.0794155\tbest: 263461.2503704 (2138)\ttotal: 1m 29s\tremaining: 5m 27s\n",
      "2160:\tlearn: 243660.7309716\ttest: 263485.6324811\tbest: 263452.8071227 (2150)\ttotal: 1m 29s\tremaining: 5m 26s\n",
      "2180:\tlearn: 243486.5402990\ttest: 263372.2901183\tbest: 263372.2901183 (2180)\ttotal: 1m 30s\tremaining: 5m 25s\n",
      "2200:\tlearn: 243313.6702804\ttest: 263332.5234054\tbest: 263332.5234054 (2200)\ttotal: 1m 31s\tremaining: 5m 24s\n",
      "2220:\tlearn: 243184.5037279\ttest: 263288.3632947\tbest: 263288.3632947 (2220)\ttotal: 1m 32s\tremaining: 5m 23s\n",
      "2240:\tlearn: 243035.4351751\ttest: 263242.6595250\tbest: 263223.8550843 (2238)\ttotal: 1m 33s\tremaining: 5m 23s\n",
      "2260:\tlearn: 242893.2077203\ttest: 263180.2229035\tbest: 263180.2229035 (2260)\ttotal: 1m 34s\tremaining: 5m 22s\n",
      "2280:\tlearn: 242768.0075461\ttest: 263144.0535307\tbest: 263137.7150683 (2279)\ttotal: 1m 35s\tremaining: 5m 21s\n",
      "2300:\tlearn: 242627.6697720\ttest: 263061.2345225\tbest: 263058.2879568 (2299)\ttotal: 1m 35s\tremaining: 5m 20s\n",
      "2320:\tlearn: 242483.9008506\ttest: 263053.5217148\tbest: 263036.9090271 (2313)\ttotal: 1m 36s\tremaining: 5m 19s\n",
      "2340:\tlearn: 242336.9212398\ttest: 262942.0617067\tbest: 262942.0617067 (2340)\ttotal: 1m 37s\tremaining: 5m 19s\n",
      "2360:\tlearn: 242180.7209686\ttest: 262812.0449265\tbest: 262812.0449265 (2360)\ttotal: 1m 38s\tremaining: 5m 18s\n",
      "2380:\tlearn: 242065.4200934\ttest: 262745.1681027\tbest: 262743.0413872 (2379)\ttotal: 1m 39s\tremaining: 5m 17s\n",
      "2400:\tlearn: 241924.0142320\ttest: 262755.4787606\tbest: 262743.0413872 (2379)\ttotal: 1m 40s\tremaining: 5m 16s\n",
      "2420:\tlearn: 241763.8652402\ttest: 262619.3629387\tbest: 262619.3629387 (2420)\ttotal: 1m 40s\tremaining: 5m 16s\n",
      "2440:\tlearn: 241637.5942970\ttest: 262595.7372104\tbest: 262595.7372104 (2440)\ttotal: 1m 41s\tremaining: 5m 15s\n",
      "2460:\tlearn: 241479.0602751\ttest: 262509.0946106\tbest: 262502.4972859 (2459)\ttotal: 1m 42s\tremaining: 5m 14s\n",
      "2480:\tlearn: 241334.0735124\ttest: 262474.5494874\tbest: 262463.5965677 (2475)\ttotal: 1m 43s\tremaining: 5m 13s\n",
      "2500:\tlearn: 241209.6937263\ttest: 262402.8491427\tbest: 262402.6501424 (2499)\ttotal: 1m 44s\tremaining: 5m 12s\n",
      "2520:\tlearn: 241089.9680636\ttest: 262415.8016896\tbest: 262387.6117117 (2507)\ttotal: 1m 45s\tremaining: 5m 11s\n",
      "2540:\tlearn: 240973.6599359\ttest: 262406.6831665\tbest: 262387.6117117 (2507)\ttotal: 1m 45s\tremaining: 5m 10s\n",
      "2560:\tlearn: 240860.3266392\ttest: 262347.1278349\tbest: 262346.2736511 (2559)\ttotal: 1m 46s\tremaining: 5m 10s\n",
      "2580:\tlearn: 240721.2152184\ttest: 262275.6779721\tbest: 262275.6779721 (2580)\ttotal: 1m 47s\tremaining: 5m 9s\n",
      "2600:\tlearn: 240581.2962705\ttest: 262293.7667297\tbest: 262258.2330416 (2591)\ttotal: 1m 48s\tremaining: 5m 8s\n",
      "2620:\tlearn: 240448.5936896\ttest: 262209.1903339\tbest: 262204.3080916 (2616)\ttotal: 1m 49s\tremaining: 5m 7s\n",
      "2640:\tlearn: 240318.0149918\ttest: 262136.6383642\tbest: 262133.6217118 (2638)\ttotal: 1m 49s\tremaining: 5m 6s\n",
      "2660:\tlearn: 240191.8158348\ttest: 262127.0481278\tbest: 262123.5229220 (2655)\ttotal: 1m 50s\tremaining: 5m 5s\n",
      "2680:\tlearn: 240053.1998693\ttest: 262093.1894069\tbest: 262092.6349448 (2678)\ttotal: 1m 51s\tremaining: 5m 4s\n",
      "2700:\tlearn: 239946.0052326\ttest: 262069.7618400\tbest: 262069.3459259 (2699)\ttotal: 1m 52s\tremaining: 5m 4s\n",
      "2720:\tlearn: 239810.6264997\ttest: 262013.6613292\tbest: 262013.6613292 (2720)\ttotal: 1m 53s\tremaining: 5m 3s\n",
      "2740:\tlearn: 239671.6611131\ttest: 262026.3432029\tbest: 261988.8449750 (2729)\ttotal: 1m 54s\tremaining: 5m 3s\n",
      "2760:\tlearn: 239538.3867733\ttest: 261972.5142494\tbest: 261958.9476175 (2755)\ttotal: 1m 55s\tremaining: 5m 2s\n",
      "2780:\tlearn: 239411.4291721\ttest: 261955.1899039\tbest: 261955.1899039 (2780)\ttotal: 1m 56s\tremaining: 5m 1s\n",
      "2800:\tlearn: 239297.4718841\ttest: 261918.6606033\tbest: 261908.6002122 (2797)\ttotal: 1m 57s\tremaining: 5m\n",
      "2820:\tlearn: 239197.1891864\ttest: 261889.8595256\tbest: 261876.8922649 (2811)\ttotal: 1m 57s\tremaining: 5m\n",
      "2840:\tlearn: 239081.0757572\ttest: 261816.7939695\tbest: 261815.6476393 (2839)\ttotal: 1m 58s\tremaining: 4m 59s\n",
      "2860:\tlearn: 238928.3092328\ttest: 261822.9771461\tbest: 261800.2761450 (2846)\ttotal: 1m 59s\tremaining: 4m 58s\n",
      "2880:\tlearn: 238789.2013408\ttest: 261782.1312948\tbest: 261779.6403269 (2877)\ttotal: 2m\tremaining: 4m 57s\n",
      "2900:\tlearn: 238674.4775758\ttest: 261672.6034958\tbest: 261672.6034958 (2900)\ttotal: 2m 1s\tremaining: 4m 56s\n",
      "2920:\tlearn: 238536.3826645\ttest: 261680.6916034\tbest: 261659.3908258 (2912)\ttotal: 2m 2s\tremaining: 4m 56s\n",
      "2940:\tlearn: 238435.8704623\ttest: 261700.1996372\tbest: 261659.3908258 (2912)\ttotal: 2m 2s\tremaining: 4m 55s\n",
      "2960:\tlearn: 238291.7835856\ttest: 261677.2310503\tbest: 261659.3908258 (2912)\ttotal: 2m 3s\tremaining: 4m 54s\n",
      "2980:\tlearn: 238153.4738072\ttest: 261700.9742193\tbest: 261659.3908258 (2912)\ttotal: 2m 4s\tremaining: 4m 53s\n",
      "3000:\tlearn: 238061.9278672\ttest: 261681.6180220\tbest: 261659.3908258 (2912)\ttotal: 2m 5s\tremaining: 4m 52s\n",
      "3020:\tlearn: 237971.8300819\ttest: 261661.3589629\tbest: 261659.3908258 (2912)\ttotal: 2m 6s\tremaining: 4m 51s\n",
      "3040:\tlearn: 237859.4684191\ttest: 261632.8243310\tbest: 261622.6422137 (3033)\ttotal: 2m 6s\tremaining: 4m 50s\n",
      "3060:\tlearn: 237727.9418463\ttest: 261613.8192362\tbest: 261611.6863461 (3057)\ttotal: 2m 7s\tremaining: 4m 49s\n",
      "3080:\tlearn: 237624.8777650\ttest: 261563.6191994\tbest: 261563.6191994 (3080)\ttotal: 2m 8s\tremaining: 4m 48s\n",
      "3100:\tlearn: 237495.9298317\ttest: 261501.7177943\tbest: 261485.7745608 (3099)\ttotal: 2m 9s\tremaining: 4m 47s\n",
      "3120:\tlearn: 237371.7938445\ttest: 261486.5939174\tbest: 261465.8698839 (3113)\ttotal: 2m 10s\tremaining: 4m 46s\n",
      "3140:\tlearn: 237260.7848414\ttest: 261514.8197884\tbest: 261465.8698839 (3113)\ttotal: 2m 10s\tremaining: 4m 45s\n",
      "3160:\tlearn: 237143.0854345\ttest: 261463.9506135\tbest: 261454.3536344 (3156)\ttotal: 2m 11s\tremaining: 4m 44s\n",
      "3180:\tlearn: 237007.7026342\ttest: 261448.8079140\tbest: 261432.8038512 (3176)\ttotal: 2m 12s\tremaining: 4m 43s\n",
      "3200:\tlearn: 236918.4301547\ttest: 261424.8320228\tbest: 261386.2408282 (3189)\ttotal: 2m 13s\tremaining: 4m 43s\n",
      "3220:\tlearn: 236796.8113264\ttest: 261378.5664920\tbest: 261373.6684615 (3217)\ttotal: 2m 14s\tremaining: 4m 42s\n",
      "3240:\tlearn: 236695.9816624\ttest: 261340.2664787\tbest: 261328.2463456 (3237)\ttotal: 2m 14s\tremaining: 4m 41s\n",
      "3260:\tlearn: 236579.0738779\ttest: 261307.3942030\tbest: 261306.8865806 (3259)\ttotal: 2m 15s\tremaining: 4m 40s\n",
      "3280:\tlearn: 236458.0005467\ttest: 261269.6366531\tbest: 261264.6706473 (3279)\ttotal: 2m 16s\tremaining: 4m 39s\n",
      "3300:\tlearn: 236323.8364880\ttest: 261243.2980719\tbest: 261234.7240426 (3294)\ttotal: 2m 17s\tremaining: 4m 39s\n",
      "3320:\tlearn: 236200.7602425\ttest: 261197.3074086\tbest: 261197.3074086 (3320)\ttotal: 2m 18s\tremaining: 4m 38s\n",
      "3340:\tlearn: 236073.0914990\ttest: 261107.9260724\tbest: 261099.4594254 (3337)\ttotal: 2m 19s\tremaining: 4m 37s\n",
      "3360:\tlearn: 235955.6204054\ttest: 261072.4201477\tbest: 261060.6009017 (3358)\ttotal: 2m 20s\tremaining: 4m 37s\n",
      "3380:\tlearn: 235859.1325870\ttest: 261094.9615442\tbest: 261060.6009017 (3358)\ttotal: 2m 21s\tremaining: 4m 36s\n",
      "3400:\tlearn: 235714.1394519\ttest: 261044.1434448\tbest: 261044.1434448 (3400)\ttotal: 2m 21s\tremaining: 4m 35s\n",
      "3420:\tlearn: 235586.7274694\ttest: 261008.6660008\tbest: 261004.0494422 (3412)\ttotal: 2m 22s\tremaining: 4m 34s\n",
      "3440:\tlearn: 235462.3118433\ttest: 261010.3815253\tbest: 260998.8617028 (3426)\ttotal: 2m 23s\tremaining: 4m 33s\n",
      "3460:\tlearn: 235354.1067802\ttest: 261002.9330050\tbest: 260997.2058515 (3458)\ttotal: 2m 24s\tremaining: 4m 32s\n",
      "3480:\tlearn: 235221.4251654\ttest: 260994.8317597\tbest: 260969.6543302 (3467)\ttotal: 2m 25s\tremaining: 4m 31s\n",
      "3500:\tlearn: 235071.5992260\ttest: 260957.3860837\tbest: 260957.3860837 (3500)\ttotal: 2m 25s\tremaining: 4m 30s\n",
      "3520:\tlearn: 234944.1868389\ttest: 260889.5724953\tbest: 260889.5724953 (3520)\ttotal: 2m 26s\tremaining: 4m 30s\n",
      "3540:\tlearn: 234829.4538823\ttest: 260850.0090556\tbest: 260850.0090556 (3540)\ttotal: 2m 27s\tremaining: 4m 29s\n",
      "3560:\tlearn: 234702.9003335\ttest: 260819.3034803\tbest: 260819.3034803 (3560)\ttotal: 2m 28s\tremaining: 4m 28s\n",
      "3580:\tlearn: 234605.1665993\ttest: 260799.6057430\tbest: 260799.6057430 (3580)\ttotal: 2m 29s\tremaining: 4m 27s\n",
      "3600:\tlearn: 234489.9206011\ttest: 260816.5748345\tbest: 260797.4420230 (3582)\ttotal: 2m 29s\tremaining: 4m 26s\n",
      "3620:\tlearn: 234374.7470497\ttest: 260782.6588202\tbest: 260772.4235585 (3617)\ttotal: 2m 30s\tremaining: 4m 25s\n",
      "3640:\tlearn: 234276.0934826\ttest: 260740.2690138\tbest: 260735.9011087 (3634)\ttotal: 2m 31s\tremaining: 4m 24s\n",
      "3660:\tlearn: 234183.5209153\ttest: 260743.8113638\tbest: 260735.9011087 (3634)\ttotal: 2m 32s\tremaining: 4m 24s\n",
      "3680:\tlearn: 234082.9022512\ttest: 260740.0346141\tbest: 260727.5996388 (3661)\ttotal: 2m 33s\tremaining: 4m 23s\n",
      "3700:\tlearn: 233976.3767429\ttest: 260702.3585282\tbest: 260692.9656171 (3695)\ttotal: 2m 34s\tremaining: 4m 22s\n",
      "3720:\tlearn: 233875.6717810\ttest: 260705.1941759\tbest: 260692.9656171 (3695)\ttotal: 2m 35s\tremaining: 4m 21s\n",
      "3740:\tlearn: 233771.6199477\ttest: 260679.8589988\tbest: 260669.6985926 (3737)\ttotal: 2m 35s\tremaining: 4m 20s\n",
      "3760:\tlearn: 233649.1347828\ttest: 260641.6356527\tbest: 260634.5702271 (3752)\ttotal: 2m 36s\tremaining: 4m 20s\n",
      "3780:\tlearn: 233555.0596802\ttest: 260613.8212417\tbest: 260604.4760961 (3777)\ttotal: 2m 37s\tremaining: 4m 19s\n",
      "3800:\tlearn: 233458.9169250\ttest: 260576.0521656\tbest: 260576.0521656 (3800)\ttotal: 2m 38s\tremaining: 4m 18s\n",
      "3820:\tlearn: 233355.4997319\ttest: 260588.5713007\tbest: 260561.4815734 (3807)\ttotal: 2m 39s\tremaining: 4m 17s\n",
      "3840:\tlearn: 233249.2603073\ttest: 260569.4578965\tbest: 260561.4815734 (3807)\ttotal: 2m 40s\tremaining: 4m 16s\n",
      "3860:\tlearn: 233148.5678060\ttest: 260560.5541621\tbest: 260549.9049853 (3851)\ttotal: 2m 41s\tremaining: 4m 16s\n",
      "3880:\tlearn: 233043.1833952\ttest: 260460.2081988\tbest: 260460.2081988 (3880)\ttotal: 2m 42s\tremaining: 4m 15s\n",
      "3900:\tlearn: 232929.8281803\ttest: 260422.2883448\tbest: 260422.2883448 (3900)\ttotal: 2m 42s\tremaining: 4m 14s\n",
      "3920:\tlearn: 232805.0100968\ttest: 260395.0067914\tbest: 260381.2051913 (3904)\ttotal: 2m 43s\tremaining: 4m 13s\n",
      "3940:\tlearn: 232693.3363068\ttest: 260347.4075302\tbest: 260343.4688482 (3937)\ttotal: 2m 44s\tremaining: 4m 12s\n",
      "3960:\tlearn: 232579.4145608\ttest: 260321.2691080\tbest: 260320.4249846 (3958)\ttotal: 2m 45s\tremaining: 4m 12s\n",
      "3980:\tlearn: 232477.3037560\ttest: 260323.3086163\tbest: 260320.4249846 (3958)\ttotal: 2m 46s\tremaining: 4m 11s\n",
      "4000:\tlearn: 232365.9715025\ttest: 260302.6863675\tbest: 260297.0144742 (3988)\ttotal: 2m 46s\tremaining: 4m 10s\n",
      "4020:\tlearn: 232284.7615255\ttest: 260247.7446971\tbest: 260247.7446971 (4020)\ttotal: 2m 47s\tremaining: 4m 9s\n",
      "4040:\tlearn: 232150.3263796\ttest: 260216.2410548\tbest: 260201.5203744 (4036)\ttotal: 2m 48s\tremaining: 4m 8s\n",
      "4060:\tlearn: 232035.2512248\ttest: 260182.8419587\tbest: 260167.3588357 (4054)\ttotal: 2m 49s\tremaining: 4m 7s\n",
      "4080:\tlearn: 231939.3732429\ttest: 260145.2922453\tbest: 260145.2922453 (4080)\ttotal: 2m 50s\tremaining: 4m 6s\n",
      "4100:\tlearn: 231850.1179172\ttest: 260140.6300638\tbest: 260131.3322196 (4082)\ttotal: 2m 50s\tremaining: 4m 5s\n",
      "4120:\tlearn: 231749.7350565\ttest: 260100.9355194\tbest: 260100.9355194 (4120)\ttotal: 2m 51s\tremaining: 4m 5s\n",
      "4140:\tlearn: 231658.8720531\ttest: 260097.6280931\tbest: 260092.5377586 (4138)\ttotal: 2m 52s\tremaining: 4m 4s\n",
      "4160:\tlearn: 231568.0632311\ttest: 260033.2777687\tbest: 260033.2777687 (4160)\ttotal: 2m 53s\tremaining: 4m 3s\n",
      "4180:\tlearn: 231465.7885358\ttest: 260018.5032925\tbest: 260014.9291476 (4177)\ttotal: 2m 54s\tremaining: 4m 2s\n",
      "4200:\tlearn: 231389.5963117\ttest: 259976.4684347\tbest: 259976.1348469 (4199)\ttotal: 2m 55s\tremaining: 4m 1s\n",
      "4220:\tlearn: 231276.9952993\ttest: 259923.6120027\tbest: 259923.6120027 (4220)\ttotal: 2m 55s\tremaining: 4m\n",
      "4240:\tlearn: 231188.2763547\ttest: 259871.2814989\tbest: 259869.9706150 (4239)\ttotal: 2m 56s\tremaining: 3m 59s\n",
      "4260:\tlearn: 231086.8949008\ttest: 259846.3829103\tbest: 259846.3829103 (4260)\ttotal: 2m 57s\tremaining: 3m 58s\n",
      "4280:\tlearn: 230994.8959231\ttest: 259849.4499615\tbest: 259834.6015834 (4263)\ttotal: 2m 58s\tremaining: 3m 57s\n",
      "4300:\tlearn: 230876.4855758\ttest: 259771.5141993\tbest: 259771.5141993 (4300)\ttotal: 2m 58s\tremaining: 3m 57s\n",
      "4320:\tlearn: 230776.4843688\ttest: 259710.4296017\tbest: 259710.4296017 (4320)\ttotal: 2m 59s\tremaining: 3m 56s\n",
      "4340:\tlearn: 230682.0663766\ttest: 259713.9934035\tbest: 259710.4296017 (4320)\ttotal: 3m\tremaining: 3m 55s\n",
      "4360:\tlearn: 230583.3662192\ttest: 259714.9215910\tbest: 259707.9167016 (4350)\ttotal: 3m 1s\tremaining: 3m 54s\n",
      "4380:\tlearn: 230496.8357276\ttest: 259676.6836458\tbest: 259676.6836458 (4380)\ttotal: 3m 2s\tremaining: 3m 53s\n",
      "4400:\tlearn: 230376.7426423\ttest: 259667.7659026\tbest: 259653.0405071 (4392)\ttotal: 3m 3s\tremaining: 3m 53s\n",
      "4420:\tlearn: 230285.8073394\ttest: 259690.8503021\tbest: 259653.0405071 (4392)\ttotal: 3m 4s\tremaining: 3m 52s\n",
      "4440:\tlearn: 230198.7775458\ttest: 259613.6654633\tbest: 259613.6654633 (4440)\ttotal: 3m 4s\tremaining: 3m 51s\n",
      "4460:\tlearn: 230082.1316882\ttest: 259549.9776140\tbest: 259549.9776140 (4460)\ttotal: 3m 5s\tremaining: 3m 50s\n",
      "4480:\tlearn: 229996.2833939\ttest: 259494.6297048\tbest: 259494.6297048 (4480)\ttotal: 3m 6s\tremaining: 3m 49s\n",
      "4500:\tlearn: 229896.3757657\ttest: 259458.6457122\tbest: 259448.7462427 (4494)\ttotal: 3m 7s\tremaining: 3m 48s\n",
      "4520:\tlearn: 229796.8878880\ttest: 259433.8072426\tbest: 259424.9994906 (4519)\ttotal: 3m 8s\tremaining: 3m 48s\n",
      "4540:\tlearn: 229725.0585408\ttest: 259401.6012617\tbest: 259398.1953600 (4537)\ttotal: 3m 8s\tremaining: 3m 47s\n",
      "4560:\tlearn: 229642.2728386\ttest: 259382.3120059\tbest: 259382.3120059 (4560)\ttotal: 3m 9s\tremaining: 3m 46s\n",
      "4580:\tlearn: 229536.2824259\ttest: 259394.3980213\tbest: 259382.3120059 (4560)\ttotal: 3m 10s\tremaining: 3m 45s\n",
      "4600:\tlearn: 229459.3193955\ttest: 259388.6580979\tbest: 259382.3120059 (4560)\ttotal: 3m 11s\tremaining: 3m 44s\n",
      "4620:\tlearn: 229370.6328102\ttest: 259335.7533187\tbest: 259335.7108860 (4618)\ttotal: 3m 12s\tremaining: 3m 43s\n",
      "4640:\tlearn: 229268.6787894\ttest: 259353.5566325\tbest: 259335.7108860 (4618)\ttotal: 3m 13s\tremaining: 3m 43s\n",
      "4660:\tlearn: 229174.6835222\ttest: 259351.1321738\tbest: 259335.7108860 (4618)\ttotal: 3m 13s\tremaining: 3m 42s\n",
      "4680:\tlearn: 229097.4139300\ttest: 259317.7543551\tbest: 259313.9858698 (4678)\ttotal: 3m 14s\tremaining: 3m 41s\n",
      "4700:\tlearn: 229029.6331481\ttest: 259288.6805988\tbest: 259285.5876584 (4696)\ttotal: 3m 15s\tremaining: 3m 40s\n",
      "4720:\tlearn: 228915.2268841\ttest: 259259.3993504\tbest: 259254.8602456 (4712)\ttotal: 3m 16s\tremaining: 3m 39s\n",
      "4740:\tlearn: 228791.7737084\ttest: 259179.3157495\tbest: 259179.3157495 (4740)\ttotal: 3m 17s\tremaining: 3m 38s\n",
      "4760:\tlearn: 228704.3153776\ttest: 259109.7911193\tbest: 259109.7911193 (4760)\ttotal: 3m 17s\tremaining: 3m 37s\n",
      "4780:\tlearn: 228621.6149809\ttest: 259123.6216375\tbest: 259089.5847142 (4773)\ttotal: 3m 18s\tremaining: 3m 37s\n",
      "4800:\tlearn: 228518.5548824\ttest: 259159.4221643\tbest: 259089.5847142 (4773)\ttotal: 3m 19s\tremaining: 3m 36s\n",
      "4820:\tlearn: 228414.0110528\ttest: 259175.8806656\tbest: 259089.5847142 (4773)\ttotal: 3m 20s\tremaining: 3m 35s\n",
      "4840:\tlearn: 228322.4851767\ttest: 259140.1586601\tbest: 259089.5847142 (4773)\ttotal: 3m 21s\tremaining: 3m 34s\n",
      "4860:\tlearn: 228221.9795675\ttest: 259134.9396558\tbest: 259089.5847142 (4773)\ttotal: 3m 21s\tremaining: 3m 33s\n",
      "4880:\tlearn: 228128.0193531\ttest: 259139.2532686\tbest: 259089.5847142 (4773)\ttotal: 3m 22s\tremaining: 3m 32s\n",
      "4900:\tlearn: 228042.4476114\ttest: 259126.8327959\tbest: 259089.5847142 (4773)\ttotal: 3m 23s\tremaining: 3m 31s\n",
      "4920:\tlearn: 227926.3855760\ttest: 259068.3233605\tbest: 259068.3233605 (4920)\ttotal: 3m 24s\tremaining: 3m 31s\n",
      "4940:\tlearn: 227826.8252206\ttest: 259074.4216767\tbest: 259036.7909049 (4933)\ttotal: 3m 25s\tremaining: 3m 30s\n",
      "4960:\tlearn: 227728.7377212\ttest: 259037.0630709\tbest: 259036.7909049 (4933)\ttotal: 3m 26s\tremaining: 3m 29s\n",
      "4980:\tlearn: 227652.8043395\ttest: 259029.3346685\tbest: 259013.9389129 (4976)\ttotal: 3m 26s\tremaining: 3m 28s\n",
      "5000:\tlearn: 227553.3946429\ttest: 258982.7700332\tbest: 258976.5864224 (4994)\ttotal: 3m 27s\tremaining: 3m 27s\n",
      "5020:\tlearn: 227450.0522184\ttest: 258999.7968557\tbest: 258968.5602776 (5012)\ttotal: 3m 28s\tremaining: 3m 26s\n",
      "5040:\tlearn: 227355.9207887\ttest: 259036.6932230\tbest: 258968.5602776 (5012)\ttotal: 3m 29s\tremaining: 3m 25s\n",
      "5060:\tlearn: 227274.8502562\ttest: 259047.6282629\tbest: 258968.5602776 (5012)\ttotal: 3m 30s\tremaining: 3m 25s\n",
      "5080:\tlearn: 227190.9502560\ttest: 259039.5871510\tbest: 258968.5602776 (5012)\ttotal: 3m 30s\tremaining: 3m 24s\n",
      "5100:\tlearn: 227094.3604280\ttest: 259040.3631979\tbest: 258968.5602776 (5012)\ttotal: 3m 31s\tremaining: 3m 23s\n",
      "5120:\tlearn: 227012.2031148\ttest: 259015.0526534\tbest: 258968.5602776 (5012)\ttotal: 3m 32s\tremaining: 3m 22s\n",
      "5140:\tlearn: 226938.3872027\ttest: 258999.0612591\tbest: 258968.5602776 (5012)\ttotal: 3m 33s\tremaining: 3m 21s\n",
      "5160:\tlearn: 226835.5464722\ttest: 258956.0535968\tbest: 258946.7222676 (5156)\ttotal: 3m 34s\tremaining: 3m 20s\n",
      "5180:\tlearn: 226737.5493227\ttest: 258925.8390704\tbest: 258925.8390704 (5180)\ttotal: 3m 34s\tremaining: 3m 19s\n",
      "5200:\tlearn: 226651.9974823\ttest: 258934.7498456\tbest: 258920.6746511 (5181)\ttotal: 3m 35s\tremaining: 3m 19s\n",
      "5220:\tlearn: 226570.1367765\ttest: 258929.6707922\tbest: 258920.6746511 (5181)\ttotal: 3m 36s\tremaining: 3m 18s\n",
      "5240:\tlearn: 226467.5045944\ttest: 258886.8275916\tbest: 258886.8275916 (5240)\ttotal: 3m 37s\tremaining: 3m 17s\n",
      "5260:\tlearn: 226363.4882709\ttest: 258840.3264723\tbest: 258833.5437200 (5253)\ttotal: 3m 38s\tremaining: 3m 16s\n",
      "5280:\tlearn: 226271.9441118\ttest: 258839.3830193\tbest: 258808.9296912 (5262)\ttotal: 3m 38s\tremaining: 3m 15s\n",
      "5300:\tlearn: 226178.3836682\ttest: 258781.8285855\tbest: 258780.0983682 (5299)\ttotal: 3m 39s\tremaining: 3m 14s\n",
      "5320:\tlearn: 226070.2010874\ttest: 258742.0362401\tbest: 258721.7258116 (5316)\ttotal: 3m 40s\tremaining: 3m 13s\n",
      "5340:\tlearn: 225975.5877361\ttest: 258696.4045327\tbest: 258686.7070091 (5338)\ttotal: 3m 41s\tremaining: 3m 13s\n",
      "5360:\tlearn: 225880.4841139\ttest: 258673.7743604\tbest: 258660.4331920 (5345)\ttotal: 3m 42s\tremaining: 3m 12s\n",
      "5380:\tlearn: 225791.1880919\ttest: 258676.8888411\tbest: 258660.4331920 (5345)\ttotal: 3m 42s\tremaining: 3m 11s\n",
      "5400:\tlearn: 225706.1500535\ttest: 258611.6312347\tbest: 258611.6312347 (5400)\ttotal: 3m 43s\tremaining: 3m 10s\n",
      "5420:\tlearn: 225628.1874692\ttest: 258606.2727732\tbest: 258606.2727732 (5420)\ttotal: 3m 44s\tremaining: 3m 9s\n",
      "5440:\tlearn: 225542.2592391\ttest: 258591.9482766\tbest: 258581.5645442 (5436)\ttotal: 3m 45s\tremaining: 3m 8s\n",
      "5460:\tlearn: 225465.1642329\ttest: 258608.0934584\tbest: 258581.5645442 (5436)\ttotal: 3m 46s\tremaining: 3m 8s\n",
      "5480:\tlearn: 225374.8425094\ttest: 258595.3414933\tbest: 258581.5645442 (5436)\ttotal: 3m 47s\tremaining: 3m 7s\n",
      "5500:\tlearn: 225292.2263787\ttest: 258568.8998795\tbest: 258568.8998795 (5500)\ttotal: 3m 47s\tremaining: 3m 6s\n",
      "5520:\tlearn: 225202.2391309\ttest: 258518.6669875\tbest: 258518.6669875 (5520)\ttotal: 3m 48s\tremaining: 3m 5s\n",
      "5540:\tlearn: 225126.5661484\ttest: 258536.0817829\tbest: 258518.5842285 (5522)\ttotal: 3m 49s\tremaining: 3m 4s\n",
      "5560:\tlearn: 225033.9917339\ttest: 258484.5238336\tbest: 258484.5238336 (5560)\ttotal: 3m 50s\tremaining: 3m 3s\n",
      "5580:\tlearn: 224939.1228024\ttest: 258463.6823261\tbest: 258454.6604550 (5574)\ttotal: 3m 51s\tremaining: 3m 2s\n",
      "5600:\tlearn: 224835.3287489\ttest: 258475.9717790\tbest: 258449.4233283 (5591)\ttotal: 3m 51s\tremaining: 3m 2s\n",
      "5620:\tlearn: 224738.1933838\ttest: 258452.7279432\tbest: 258449.4233283 (5591)\ttotal: 3m 52s\tremaining: 3m 1s\n",
      "5640:\tlearn: 224653.7952793\ttest: 258400.1002288\tbest: 258392.1378987 (5639)\ttotal: 3m 53s\tremaining: 3m\n",
      "5660:\tlearn: 224572.6844606\ttest: 258433.1983117\tbest: 258383.6670991 (5653)\ttotal: 3m 54s\tremaining: 2m 59s\n",
      "5680:\tlearn: 224491.0523383\ttest: 258402.5366959\tbest: 258383.6670991 (5653)\ttotal: 3m 55s\tremaining: 2m 58s\n",
      "5700:\tlearn: 224404.3505282\ttest: 258422.1801426\tbest: 258383.6670991 (5653)\ttotal: 3m 56s\tremaining: 2m 58s\n",
      "5720:\tlearn: 224320.5145978\ttest: 258383.3800425\tbest: 258383.3800425 (5720)\ttotal: 3m 56s\tremaining: 2m 57s\n",
      "5740:\tlearn: 224245.6137164\ttest: 258347.4468460\tbest: 258347.4468460 (5740)\ttotal: 3m 57s\tremaining: 2m 56s\n",
      "5760:\tlearn: 224183.0447713\ttest: 258323.3693975\tbest: 258323.3693975 (5760)\ttotal: 3m 58s\tremaining: 2m 55s\n",
      "5780:\tlearn: 224085.4618285\ttest: 258296.6812859\tbest: 258296.6812859 (5780)\ttotal: 3m 59s\tremaining: 2m 54s\n",
      "5800:\tlearn: 224012.9155693\ttest: 258241.0713657\tbest: 258241.0713657 (5800)\ttotal: 4m\tremaining: 2m 53s\n",
      "5820:\tlearn: 223927.2851699\ttest: 258190.6397400\tbest: 258190.6397400 (5820)\ttotal: 4m 1s\tremaining: 2m 53s\n",
      "5840:\tlearn: 223834.8251848\ttest: 258152.2903122\tbest: 258148.5865517 (5838)\ttotal: 4m 1s\tremaining: 2m 52s\n",
      "5860:\tlearn: 223748.8550552\ttest: 258121.5089760\tbest: 258110.0856604 (5858)\ttotal: 4m 2s\tremaining: 2m 51s\n",
      "5880:\tlearn: 223661.6567098\ttest: 258081.3339123\tbest: 258071.6897387 (5877)\ttotal: 4m 3s\tremaining: 2m 50s\n",
      "5900:\tlearn: 223575.6361145\ttest: 258090.6717360\tbest: 258071.6897387 (5877)\ttotal: 4m 4s\tremaining: 2m 49s\n",
      "5920:\tlearn: 223495.0625828\ttest: 258059.4893883\tbest: 258057.6035032 (5919)\ttotal: 4m 5s\tremaining: 2m 48s\n",
      "5940:\tlearn: 223420.4759183\ttest: 258036.2528030\tbest: 258033.7595145 (5928)\ttotal: 4m 6s\tremaining: 2m 48s\n",
      "5960:\tlearn: 223355.2199541\ttest: 258027.6885898\tbest: 258020.1752645 (5951)\ttotal: 4m 6s\tremaining: 2m 47s\n",
      "5980:\tlearn: 223276.2974282\ttest: 257979.1126879\tbest: 257969.2764855 (5978)\ttotal: 4m 7s\tremaining: 2m 46s\n",
      "6000:\tlearn: 223196.8644807\ttest: 257945.9864760\tbest: 257939.5098922 (5997)\ttotal: 4m 8s\tremaining: 2m 45s\n",
      "6020:\tlearn: 223126.2912703\ttest: 257942.7278780\tbest: 257937.0857626 (6019)\ttotal: 4m 9s\tremaining: 2m 44s\n",
      "6040:\tlearn: 223063.7115198\ttest: 257948.8277916\tbest: 257937.0857626 (6019)\ttotal: 4m 10s\tremaining: 2m 43s\n",
      "6060:\tlearn: 222981.3675458\ttest: 257917.4854789\tbest: 257905.1461653 (6050)\ttotal: 4m 10s\tremaining: 2m 43s\n",
      "6080:\tlearn: 222899.1577909\ttest: 257931.3478509\tbest: 257905.1461653 (6050)\ttotal: 4m 11s\tremaining: 2m 42s\n",
      "6100:\tlearn: 222811.5016600\ttest: 257913.3026971\tbest: 257905.1461653 (6050)\ttotal: 4m 12s\tremaining: 2m 41s\n",
      "6120:\tlearn: 222722.4470923\ttest: 257889.6807731\tbest: 257871.9138117 (6111)\ttotal: 4m 13s\tremaining: 2m 40s\n",
      "6140:\tlearn: 222633.3105924\ttest: 257834.8172140\tbest: 257821.3890766 (6136)\ttotal: 4m 14s\tremaining: 2m 39s\n",
      "6160:\tlearn: 222552.6455636\ttest: 257815.2027809\tbest: 257807.7648518 (6156)\ttotal: 4m 15s\tremaining: 2m 38s\n",
      "6180:\tlearn: 222475.6564278\ttest: 257821.7436752\tbest: 257807.7648518 (6156)\ttotal: 4m 15s\tremaining: 2m 38s\n",
      "6200:\tlearn: 222393.7253941\ttest: 257817.9980119\tbest: 257807.7648518 (6156)\ttotal: 4m 16s\tremaining: 2m 37s\n",
      "6220:\tlearn: 222327.8016695\ttest: 257784.6431229\tbest: 257784.6431229 (6220)\ttotal: 4m 17s\tremaining: 2m 36s\n",
      "6240:\tlearn: 222229.7691175\ttest: 257777.9820635\tbest: 257759.9685900 (6224)\ttotal: 4m 18s\tremaining: 2m 35s\n",
      "6260:\tlearn: 222150.3843677\ttest: 257758.7737503\tbest: 257753.4087297 (6259)\ttotal: 4m 19s\tremaining: 2m 34s\n",
      "6280:\tlearn: 222081.0263613\ttest: 257760.5152292\tbest: 257737.9633988 (6264)\ttotal: 4m 20s\tremaining: 2m 33s\n",
      "6300:\tlearn: 222006.7643323\ttest: 257753.4803305\tbest: 257737.9633988 (6264)\ttotal: 4m 20s\tremaining: 2m 33s\n",
      "6320:\tlearn: 221922.5630391\ttest: 257705.0030551\tbest: 257704.0820827 (6317)\ttotal: 4m 21s\tremaining: 2m 32s\n",
      "6340:\tlearn: 221837.2149829\ttest: 257691.3841250\tbest: 257691.2236004 (6339)\ttotal: 4m 22s\tremaining: 2m 31s\n",
      "6360:\tlearn: 221762.1268038\ttest: 257721.1863532\tbest: 257690.5396024 (6341)\ttotal: 4m 23s\tremaining: 2m 30s\n",
      "6380:\tlearn: 221662.0570477\ttest: 257707.6194478\tbest: 257690.5396024 (6341)\ttotal: 4m 24s\tremaining: 2m 29s\n",
      "6400:\tlearn: 221589.8001141\ttest: 257731.5079596\tbest: 257690.5396024 (6341)\ttotal: 4m 24s\tremaining: 2m 28s\n",
      "6420:\tlearn: 221515.2298407\ttest: 257747.2307649\tbest: 257690.5396024 (6341)\ttotal: 4m 25s\tremaining: 2m 28s\n",
      "6440:\tlearn: 221444.5751018\ttest: 257756.0454371\tbest: 257690.5396024 (6341)\ttotal: 4m 26s\tremaining: 2m 27s\n",
      "6460:\tlearn: 221374.2087626\ttest: 257751.1107722\tbest: 257690.5396024 (6341)\ttotal: 4m 27s\tremaining: 2m 26s\n",
      "6480:\tlearn: 221282.4564660\ttest: 257703.3309813\tbest: 257690.5396024 (6341)\ttotal: 4m 28s\tremaining: 2m 25s\n",
      "6500:\tlearn: 221210.7896486\ttest: 257683.8968690\tbest: 257678.0769542 (6499)\ttotal: 4m 28s\tremaining: 2m 24s\n",
      "6520:\tlearn: 221134.0722874\ttest: 257652.9166709\tbest: 257650.1350938 (6517)\ttotal: 4m 29s\tremaining: 2m 23s\n",
      "6540:\tlearn: 221063.9709361\ttest: 257625.6158117\tbest: 257625.6158117 (6540)\ttotal: 4m 30s\tremaining: 2m 23s\n",
      "6560:\tlearn: 220961.2731391\ttest: 257624.5022713\tbest: 257622.3853685 (6559)\ttotal: 4m 31s\tremaining: 2m 22s\n",
      "6580:\tlearn: 220897.9391112\ttest: 257608.8645656\tbest: 257605.8759168 (6578)\ttotal: 4m 32s\tremaining: 2m 21s\n",
      "6600:\tlearn: 220842.7885613\ttest: 257618.4518918\tbest: 257604.7227148 (6588)\ttotal: 4m 33s\tremaining: 2m 20s\n",
      "6620:\tlearn: 220762.8515618\ttest: 257579.5433383\tbest: 257574.6249950 (6619)\ttotal: 4m 34s\tremaining: 2m 19s\n",
      "6640:\tlearn: 220673.9922367\ttest: 257585.3223651\tbest: 257574.6249950 (6619)\ttotal: 4m 34s\tremaining: 2m 19s\n",
      "6660:\tlearn: 220604.1857671\ttest: 257576.5873583\tbest: 257567.3051243 (6651)\ttotal: 4m 35s\tremaining: 2m 18s\n",
      "6680:\tlearn: 220503.0032485\ttest: 257541.2857436\tbest: 257539.6674397 (6676)\ttotal: 4m 36s\tremaining: 2m 17s\n",
      "6700:\tlearn: 220435.3212958\ttest: 257560.9217208\tbest: 257539.6674397 (6676)\ttotal: 4m 37s\tremaining: 2m 16s\n",
      "6720:\tlearn: 220344.1326454\ttest: 257548.5806808\tbest: 257539.6674397 (6676)\ttotal: 4m 38s\tremaining: 2m 15s\n",
      "6740:\tlearn: 220246.4450291\ttest: 257550.0722419\tbest: 257513.7540694 (6732)\ttotal: 4m 39s\tremaining: 2m 15s\n",
      "6760:\tlearn: 220166.5402877\ttest: 257527.0999025\tbest: 257513.7540694 (6732)\ttotal: 4m 40s\tremaining: 2m 14s\n",
      "6780:\tlearn: 220090.9336386\ttest: 257479.3734482\tbest: 257479.1390605 (6779)\ttotal: 4m 41s\tremaining: 2m 13s\n",
      "6800:\tlearn: 220010.0077780\ttest: 257465.1857303\tbest: 257465.1857303 (6800)\ttotal: 4m 42s\tremaining: 2m 12s\n",
      "6820:\tlearn: 219917.6229209\ttest: 257442.2362051\tbest: 257441.5222085 (6819)\ttotal: 4m 43s\tremaining: 2m 11s\n",
      "6840:\tlearn: 219836.9034884\ttest: 257417.3646795\tbest: 257409.6920484 (6833)\ttotal: 4m 43s\tremaining: 2m 11s\n",
      "6860:\tlearn: 219752.9656815\ttest: 257449.2853217\tbest: 257409.6920484 (6833)\ttotal: 4m 44s\tremaining: 2m 10s\n",
      "6880:\tlearn: 219673.4473379\ttest: 257427.5455929\tbest: 257409.6920484 (6833)\ttotal: 4m 45s\tremaining: 2m 9s\n",
      "6900:\tlearn: 219601.1877509\ttest: 257419.4141947\tbest: 257409.6920484 (6833)\ttotal: 4m 46s\tremaining: 2m 8s\n",
      "6920:\tlearn: 219497.3122377\ttest: 257402.0704639\tbest: 257372.6675344 (6911)\ttotal: 4m 47s\tremaining: 2m 7s\n",
      "6940:\tlearn: 219436.1700772\ttest: 257397.9559685\tbest: 257372.6675344 (6911)\ttotal: 4m 48s\tremaining: 2m 7s\n",
      "6960:\tlearn: 219371.2140399\ttest: 257368.3672158\tbest: 257364.9562158 (6958)\ttotal: 4m 49s\tremaining: 2m 6s\n",
      "6980:\tlearn: 219303.0946504\ttest: 257348.4156674\tbest: 257342.9828646 (6978)\ttotal: 4m 49s\tremaining: 2m 5s\n",
      "7000:\tlearn: 219219.2597008\ttest: 257323.9013611\tbest: 257323.9013611 (7000)\ttotal: 4m 50s\tremaining: 2m 4s\n",
      "7020:\tlearn: 219154.3724431\ttest: 257318.1435263\tbest: 257305.3238314 (7017)\ttotal: 4m 51s\tremaining: 2m 3s\n",
      "7040:\tlearn: 219082.8154152\ttest: 257315.6440533\tbest: 257305.3238314 (7017)\ttotal: 4m 52s\tremaining: 2m 2s\n",
      "7060:\tlearn: 219018.3059385\ttest: 257314.7488254\tbest: 257304.5053073 (7056)\ttotal: 4m 53s\tremaining: 2m 2s\n",
      "7080:\tlearn: 218956.1502316\ttest: 257301.4667590\tbest: 257301.4667590 (7080)\ttotal: 4m 54s\tremaining: 2m 1s\n",
      "7100:\tlearn: 218870.1825625\ttest: 257289.2168640\tbest: 257289.2168640 (7100)\ttotal: 4m 55s\tremaining: 2m\n",
      "7120:\tlearn: 218808.8765134\ttest: 257266.1648286\tbest: 257262.5499322 (7119)\ttotal: 4m 55s\tremaining: 1m 59s\n",
      "7140:\tlearn: 218740.2456034\ttest: 257279.7614487\tbest: 257262.5499322 (7119)\ttotal: 4m 56s\tremaining: 1m 58s\n",
      "7160:\tlearn: 218663.5359037\ttest: 257293.2573177\tbest: 257262.5499322 (7119)\ttotal: 4m 57s\tremaining: 1m 57s\n",
      "7180:\tlearn: 218589.9467615\ttest: 257273.8853114\tbest: 257255.3292389 (7177)\ttotal: 4m 58s\tremaining: 1m 57s\n",
      "7200:\tlearn: 218495.6377057\ttest: 257241.9345289\tbest: 257241.9345289 (7200)\ttotal: 4m 59s\tremaining: 1m 56s\n",
      "7220:\tlearn: 218425.7594202\ttest: 257195.0160178\tbest: 257192.9910493 (7216)\ttotal: 5m\tremaining: 1m 55s\n",
      "7240:\tlearn: 218364.3220849\ttest: 257183.9728196\tbest: 257183.9728196 (7240)\ttotal: 5m\tremaining: 1m 54s\n",
      "7260:\tlearn: 218294.3700280\ttest: 257197.0293088\tbest: 257180.0534238 (7246)\ttotal: 5m 1s\tremaining: 1m 53s\n",
      "7280:\tlearn: 218214.6453444\ttest: 257175.7529262\tbest: 257175.6278856 (7277)\ttotal: 5m 2s\tremaining: 1m 52s\n",
      "7300:\tlearn: 218135.5646493\ttest: 257170.3682212\tbest: 257162.0608478 (7287)\ttotal: 5m 3s\tremaining: 1m 52s\n",
      "7320:\tlearn: 218067.0919117\ttest: 257170.4704045\tbest: 257161.3911289 (7305)\ttotal: 5m 4s\tremaining: 1m 51s\n",
      "7340:\tlearn: 217990.9992879\ttest: 257145.5823444\tbest: 257125.5424828 (7333)\ttotal: 5m 5s\tremaining: 1m 50s\n",
      "7360:\tlearn: 217911.1153393\ttest: 257147.1775076\tbest: 257125.5424828 (7333)\ttotal: 5m 6s\tremaining: 1m 49s\n",
      "7380:\tlearn: 217837.1062240\ttest: 257159.6122673\tbest: 257125.5424828 (7333)\ttotal: 5m 6s\tremaining: 1m 48s\n",
      "7400:\tlearn: 217779.3366567\ttest: 257160.4247040\tbest: 257125.5424828 (7333)\ttotal: 5m 7s\tremaining: 1m 48s\n",
      "7420:\tlearn: 217697.0491479\ttest: 257139.0750660\tbest: 257125.5424828 (7333)\ttotal: 5m 8s\tremaining: 1m 47s\n",
      "7440:\tlearn: 217625.5468929\ttest: 257130.6925654\tbest: 257116.9315827 (7421)\ttotal: 5m 9s\tremaining: 1m 46s\n",
      "7460:\tlearn: 217551.4936878\ttest: 257083.3237651\tbest: 257083.3237651 (7460)\ttotal: 5m 10s\tremaining: 1m 45s\n",
      "7480:\tlearn: 217483.8981982\ttest: 257075.6488621\tbest: 257062.5355756 (7475)\ttotal: 5m 11s\tremaining: 1m 44s\n",
      "7500:\tlearn: 217410.9687667\ttest: 257061.1435583\tbest: 257051.7529129 (7489)\ttotal: 5m 11s\tremaining: 1m 43s\n",
      "7520:\tlearn: 217352.0619518\ttest: 257051.4476327\tbest: 257050.6972579 (7518)\ttotal: 5m 12s\tremaining: 1m 43s\n",
      "7540:\tlearn: 217261.1880622\ttest: 257025.9955215\tbest: 257013.5354640 (7536)\ttotal: 5m 13s\tremaining: 1m 42s\n",
      "7560:\tlearn: 217198.3778047\ttest: 257008.2137881\tbest: 256997.3548156 (7547)\ttotal: 5m 14s\tremaining: 1m 41s\n",
      "7580:\tlearn: 217137.9725694\ttest: 257015.1064174\tbest: 256995.6131479 (7575)\ttotal: 5m 15s\tremaining: 1m 40s\n",
      "7600:\tlearn: 217063.9493337\ttest: 257007.5376969\tbest: 256995.6131479 (7575)\ttotal: 5m 15s\tremaining: 1m 39s\n",
      "7620:\tlearn: 216987.7182055\ttest: 256973.0570723\tbest: 256969.1828344 (7619)\ttotal: 5m 16s\tremaining: 1m 38s\n",
      "7640:\tlearn: 216922.7959891\ttest: 256990.9040574\tbest: 256969.1828344 (7619)\ttotal: 5m 17s\tremaining: 1m 38s\n",
      "7660:\tlearn: 216846.6414537\ttest: 256990.2766475\tbest: 256969.1828344 (7619)\ttotal: 5m 18s\tremaining: 1m 37s\n",
      "7680:\tlearn: 216779.9974006\ttest: 256968.5612447\tbest: 256968.5612447 (7680)\ttotal: 5m 19s\tremaining: 1m 36s\n",
      "7700:\tlearn: 216718.7930029\ttest: 256988.2683473\tbest: 256968.5612447 (7680)\ttotal: 5m 19s\tremaining: 1m 35s\n",
      "7720:\tlearn: 216648.9381141\ttest: 256950.2347463\tbest: 256943.3975567 (7718)\ttotal: 5m 20s\tremaining: 1m 34s\n",
      "7740:\tlearn: 216557.2939999\ttest: 256973.1214108\tbest: 256943.3975567 (7718)\ttotal: 5m 21s\tremaining: 1m 33s\n",
      "7760:\tlearn: 216500.8878665\ttest: 256986.9710100\tbest: 256943.3975567 (7718)\ttotal: 5m 22s\tremaining: 1m 32s\n",
      "7780:\tlearn: 216454.5305327\ttest: 256968.7825342\tbest: 256943.3975567 (7718)\ttotal: 5m 22s\tremaining: 1m 32s\n",
      "7800:\tlearn: 216365.0837731\ttest: 256975.6341024\tbest: 256943.3975567 (7718)\ttotal: 5m 23s\tremaining: 1m 31s\n",
      "7820:\tlearn: 216302.2751681\ttest: 256976.2463715\tbest: 256943.3975567 (7718)\ttotal: 5m 24s\tremaining: 1m 30s\n",
      "7840:\tlearn: 216230.0213205\ttest: 256965.7308082\tbest: 256943.3975567 (7718)\ttotal: 5m 25s\tremaining: 1m 29s\n",
      "7860:\tlearn: 216154.8455002\ttest: 256978.6529712\tbest: 256943.3975567 (7718)\ttotal: 5m 26s\tremaining: 1m 28s\n",
      "7880:\tlearn: 216083.9731473\ttest: 256962.8179736\tbest: 256943.3975567 (7718)\ttotal: 5m 26s\tremaining: 1m 27s\n",
      "7900:\tlearn: 216015.2548150\ttest: 256966.5989140\tbest: 256943.3975567 (7718)\ttotal: 5m 27s\tremaining: 1m 27s\n",
      "7920:\tlearn: 215952.7944482\ttest: 256938.7157426\tbest: 256935.2204857 (7913)\ttotal: 5m 28s\tremaining: 1m 26s\n",
      "7940:\tlearn: 215889.7368907\ttest: 256927.2511446\tbest: 256925.6910984 (7939)\ttotal: 5m 29s\tremaining: 1m 25s\n",
      "7960:\tlearn: 215814.5474920\ttest: 256912.3581060\tbest: 256912.3581060 (7960)\ttotal: 5m 30s\tremaining: 1m 24s\n",
      "7980:\tlearn: 215760.0682501\ttest: 256898.2166649\tbest: 256881.4091443 (7970)\ttotal: 5m 30s\tremaining: 1m 23s\n",
      "8000:\tlearn: 215694.3352515\ttest: 256876.5309504\tbest: 256876.3434467 (7999)\ttotal: 5m 31s\tremaining: 1m 22s\n",
      "8020:\tlearn: 215610.4467794\ttest: 256869.4631669\tbest: 256862.9678613 (8013)\ttotal: 5m 32s\tremaining: 1m 22s\n",
      "8040:\tlearn: 215535.1954208\ttest: 256880.1534971\tbest: 256862.9678613 (8013)\ttotal: 5m 33s\tremaining: 1m 21s\n",
      "8060:\tlearn: 215467.8199197\ttest: 256891.5863039\tbest: 256862.9678613 (8013)\ttotal: 5m 34s\tremaining: 1m 20s\n",
      "8080:\tlearn: 215384.4281011\ttest: 256836.6407757\tbest: 256833.3554189 (8077)\ttotal: 5m 34s\tremaining: 1m 19s\n",
      "8100:\tlearn: 215319.5972220\ttest: 256840.4396074\tbest: 256833.3554189 (8077)\ttotal: 5m 35s\tremaining: 1m 18s\n",
      "8120:\tlearn: 215251.4843535\ttest: 256832.1346637\tbest: 256828.7522719 (8117)\ttotal: 5m 36s\tremaining: 1m 17s\n",
      "8140:\tlearn: 215198.4051542\ttest: 256825.1902194\tbest: 256815.7808771 (8129)\ttotal: 5m 37s\tremaining: 1m 17s\n",
      "8160:\tlearn: 215136.5617669\ttest: 256849.8315086\tbest: 256815.7808771 (8129)\ttotal: 5m 38s\tremaining: 1m 16s\n",
      "8180:\tlearn: 215045.5033448\ttest: 256804.0007308\tbest: 256804.0007308 (8180)\ttotal: 5m 38s\tremaining: 1m 15s\n",
      "8200:\tlearn: 214972.0367993\ttest: 256816.8070340\tbest: 256803.6187903 (8181)\ttotal: 5m 39s\tremaining: 1m 14s\n",
      "8220:\tlearn: 214918.0554054\ttest: 256764.5882859\tbest: 256764.5882859 (8220)\ttotal: 5m 40s\tremaining: 1m 13s\n",
      "8240:\tlearn: 214843.8945273\ttest: 256711.4134991\tbest: 256708.7830660 (8233)\ttotal: 5m 41s\tremaining: 1m 12s\n",
      "8260:\tlearn: 214779.0142968\ttest: 256681.5558697\tbest: 256679.3138980 (8258)\ttotal: 5m 42s\tremaining: 1m 12s\n",
      "8280:\tlearn: 214717.3569176\ttest: 256673.1814340\tbest: 256667.6409119 (8271)\ttotal: 5m 42s\tremaining: 1m 11s\n",
      "8300:\tlearn: 214654.5251047\ttest: 256672.8277044\tbest: 256664.1589102 (8294)\ttotal: 5m 43s\tremaining: 1m 10s\n",
      "8320:\tlearn: 214591.3921364\ttest: 256648.0967125\tbest: 256640.7912050 (8316)\ttotal: 5m 44s\tremaining: 1m 9s\n",
      "8340:\tlearn: 214519.5799214\ttest: 256636.5259015\tbest: 256625.8028247 (8334)\ttotal: 5m 45s\tremaining: 1m 8s\n",
      "8360:\tlearn: 214460.3272706\ttest: 256615.8355537\tbest: 256608.8501255 (8357)\ttotal: 5m 46s\tremaining: 1m 7s\n",
      "8380:\tlearn: 214373.6858530\ttest: 256588.1074703\tbest: 256586.2763222 (8376)\ttotal: 5m 46s\tremaining: 1m 7s\n",
      "8400:\tlearn: 214289.5055665\ttest: 256574.0587590\tbest: 256566.6449722 (8391)\ttotal: 5m 47s\tremaining: 1m 6s\n",
      "8420:\tlearn: 214222.9861620\ttest: 256571.7565500\tbest: 256562.7007314 (8406)\ttotal: 5m 48s\tremaining: 1m 5s\n",
      "8440:\tlearn: 214151.2897785\ttest: 256530.2030000\tbest: 256526.4178080 (8439)\ttotal: 5m 49s\tremaining: 1m 4s\n",
      "8460:\tlearn: 214072.5379190\ttest: 256523.4389808\tbest: 256514.3121932 (8459)\ttotal: 5m 50s\tremaining: 1m 3s\n",
      "8480:\tlearn: 214018.5229116\ttest: 256504.7242706\tbest: 256503.4010227 (8478)\ttotal: 5m 50s\tremaining: 1m 2s\n",
      "8500:\tlearn: 213953.7955479\ttest: 256454.1986149\tbest: 256454.1986149 (8500)\ttotal: 5m 51s\tremaining: 1m 2s\n",
      "8520:\tlearn: 213887.1358801\ttest: 256447.5914618\tbest: 256432.3958309 (8506)\ttotal: 5m 52s\tremaining: 1m 1s\n",
      "8540:\tlearn: 213820.9236662\ttest: 256398.5496379\tbest: 256392.9374099 (8537)\ttotal: 5m 53s\tremaining: 1m\n",
      "8560:\tlearn: 213743.0018364\ttest: 256357.4248412\tbest: 256357.4248412 (8560)\ttotal: 5m 54s\tremaining: 59.5s\n",
      "8580:\tlearn: 213658.5699315\ttest: 256340.8964180\tbest: 256337.5132347 (8578)\ttotal: 5m 54s\tremaining: 58.7s\n",
      "8600:\tlearn: 213597.7570006\ttest: 256353.7825564\tbest: 256333.0845350 (8587)\ttotal: 5m 55s\tremaining: 57.8s\n",
      "8620:\tlearn: 213521.9580421\ttest: 256341.3636051\tbest: 256331.3272733 (8614)\ttotal: 5m 56s\tremaining: 57s\n",
      "8640:\tlearn: 213462.6234304\ttest: 256346.2121115\tbest: 256331.3272733 (8614)\ttotal: 5m 57s\tremaining: 56.2s\n",
      "8660:\tlearn: 213385.3988473\ttest: 256290.5616814\tbest: 256258.3315710 (8651)\ttotal: 5m 58s\tremaining: 55.4s\n",
      "8680:\tlearn: 213315.2837124\ttest: 256285.4138122\tbest: 256258.3315710 (8651)\ttotal: 5m 58s\tremaining: 54.5s\n",
      "8700:\tlearn: 213239.5614931\ttest: 256301.3221905\tbest: 256258.3315710 (8651)\ttotal: 5m 59s\tremaining: 53.7s\n",
      "8720:\tlearn: 213178.0984823\ttest: 256267.5312907\tbest: 256258.3315710 (8651)\ttotal: 6m\tremaining: 52.9s\n",
      "8740:\tlearn: 213099.4808373\ttest: 256265.1069185\tbest: 256250.5755374 (8735)\ttotal: 6m 1s\tremaining: 52s\n",
      "8760:\tlearn: 213025.2249384\ttest: 256293.2904688\tbest: 256250.5755374 (8735)\ttotal: 6m 1s\tremaining: 51.2s\n",
      "8780:\tlearn: 212948.7084209\ttest: 256295.4940165\tbest: 256250.5755374 (8735)\ttotal: 6m 2s\tremaining: 50.4s\n",
      "8800:\tlearn: 212897.0580948\ttest: 256287.6122599\tbest: 256250.5755374 (8735)\ttotal: 6m 3s\tremaining: 49.5s\n",
      "8820:\tlearn: 212823.0335104\ttest: 256292.3109266\tbest: 256250.5755374 (8735)\ttotal: 6m 4s\tremaining: 48.7s\n",
      "8840:\tlearn: 212729.3429718\ttest: 256251.0426795\tbest: 256250.5755374 (8735)\ttotal: 6m 5s\tremaining: 47.9s\n",
      "8860:\tlearn: 212668.5791188\ttest: 256232.8713865\tbest: 256230.8125586 (8858)\ttotal: 6m 6s\tremaining: 47s\n",
      "8880:\tlearn: 212602.5061344\ttest: 256242.5193636\tbest: 256230.8125586 (8858)\ttotal: 6m 6s\tremaining: 46.2s\n",
      "8900:\tlearn: 212546.9654863\ttest: 256250.5916981\tbest: 256230.8125586 (8858)\ttotal: 6m 7s\tremaining: 45.4s\n",
      "8920:\tlearn: 212482.5493082\ttest: 256238.0851864\tbest: 256230.8125586 (8858)\ttotal: 6m 8s\tremaining: 44.6s\n",
      "8940:\tlearn: 212417.4018114\ttest: 256260.0546259\tbest: 256230.8125586 (8858)\ttotal: 6m 9s\tremaining: 43.7s\n",
      "8960:\tlearn: 212359.2516557\ttest: 256222.7731371\tbest: 256217.5712351 (8956)\ttotal: 6m 9s\tremaining: 42.9s\n",
      "8980:\tlearn: 212309.0189792\ttest: 256214.3138244\tbest: 256207.1406885 (8974)\ttotal: 6m 10s\tremaining: 42.1s\n",
      "9000:\tlearn: 212257.1485877\ttest: 256192.5767819\tbest: 256190.6416792 (8999)\ttotal: 6m 11s\tremaining: 41.2s\n",
      "9020:\tlearn: 212182.4130277\ttest: 256195.0660871\tbest: 256176.8842118 (9010)\ttotal: 6m 12s\tremaining: 40.4s\n",
      "9040:\tlearn: 212105.6928190\ttest: 256167.4232974\tbest: 256167.4232974 (9040)\ttotal: 6m 13s\tremaining: 39.6s\n",
      "9060:\tlearn: 212059.2795141\ttest: 256146.6592598\tbest: 256139.1901314 (9048)\ttotal: 6m 13s\tremaining: 38.8s\n",
      "9080:\tlearn: 212004.7354974\ttest: 256162.7572225\tbest: 256139.1901314 (9048)\ttotal: 6m 14s\tremaining: 37.9s\n",
      "9100:\tlearn: 211939.9397513\ttest: 256134.6783697\tbest: 256126.9545804 (9089)\ttotal: 6m 15s\tremaining: 37.1s\n",
      "9120:\tlearn: 211863.4843728\ttest: 256125.4740817\tbest: 256125.4740817 (9120)\ttotal: 6m 16s\tremaining: 36.3s\n",
      "9140:\tlearn: 211813.2030075\ttest: 256123.5996467\tbest: 256116.6749324 (9122)\ttotal: 6m 17s\tremaining: 35.4s\n",
      "9160:\tlearn: 211735.7580861\ttest: 256091.7455029\tbest: 256080.7705062 (9152)\ttotal: 6m 17s\tremaining: 34.6s\n",
      "9180:\tlearn: 211660.8967107\ttest: 256045.7494762\tbest: 256043.3857960 (9170)\ttotal: 6m 18s\tremaining: 33.8s\n",
      "9200:\tlearn: 211617.0778346\ttest: 256039.5673917\tbest: 256039.5673917 (9200)\ttotal: 6m 19s\tremaining: 33s\n",
      "9220:\tlearn: 211559.6259076\ttest: 256035.0056107\tbest: 256033.3439134 (9210)\ttotal: 6m 20s\tremaining: 32.1s\n",
      "9240:\tlearn: 211509.2605165\ttest: 256001.4969786\tbest: 255996.6254990 (9235)\ttotal: 6m 21s\tremaining: 31.3s\n",
      "9260:\tlearn: 211423.6463209\ttest: 255968.6004497\tbest: 255952.8103119 (9257)\ttotal: 6m 21s\tremaining: 30.5s\n",
      "9280:\tlearn: 211349.1162482\ttest: 255949.6206325\tbest: 255948.6002424 (9279)\ttotal: 6m 22s\tremaining: 29.6s\n",
      "9300:\tlearn: 211273.7706275\ttest: 255942.5731088\tbest: 255927.0845984 (9288)\ttotal: 6m 23s\tremaining: 28.8s\n",
      "9320:\tlearn: 211199.0692061\ttest: 255916.8240269\tbest: 255916.8240269 (9320)\ttotal: 6m 24s\tremaining: 28s\n",
      "9340:\tlearn: 211120.5380187\ttest: 255888.0228856\tbest: 255884.6311925 (9339)\ttotal: 6m 25s\tremaining: 27.2s\n",
      "9360:\tlearn: 211055.3269866\ttest: 255896.3623349\tbest: 255884.6311925 (9339)\ttotal: 6m 25s\tremaining: 26.3s\n",
      "9380:\tlearn: 210994.5639298\ttest: 255886.6022435\tbest: 255862.3886885 (9369)\ttotal: 6m 26s\tremaining: 25.5s\n",
      "9400:\tlearn: 210931.3800123\ttest: 255865.8270973\tbest: 255861.6705013 (9399)\ttotal: 6m 27s\tremaining: 24.7s\n",
      "9420:\tlearn: 210874.0968250\ttest: 255861.9008074\tbest: 255860.2653999 (9411)\ttotal: 6m 28s\tremaining: 23.9s\n",
      "9440:\tlearn: 210820.7975584\ttest: 255844.6865572\tbest: 255844.6865572 (9440)\ttotal: 6m 29s\tremaining: 23s\n",
      "9460:\tlearn: 210744.8371574\ttest: 255804.4303049\tbest: 255804.4303049 (9460)\ttotal: 6m 29s\tremaining: 22.2s\n",
      "9480:\tlearn: 210690.5198455\ttest: 255787.3424445\tbest: 255774.5451741 (9475)\ttotal: 6m 30s\tremaining: 21.4s\n",
      "9500:\tlearn: 210621.9409857\ttest: 255772.1977675\tbest: 255767.4715783 (9488)\ttotal: 6m 31s\tremaining: 20.6s\n",
      "9520:\tlearn: 210568.5326669\ttest: 255753.0904449\tbest: 255753.0904449 (9520)\ttotal: 6m 32s\tremaining: 19.7s\n",
      "9540:\tlearn: 210496.1298816\ttest: 255734.9546279\tbest: 255734.9546279 (9540)\ttotal: 6m 33s\tremaining: 18.9s\n",
      "9560:\tlearn: 210431.5405628\ttest: 255709.2004038\tbest: 255704.4482847 (9551)\ttotal: 6m 33s\tremaining: 18.1s\n",
      "9580:\tlearn: 210374.6739569\ttest: 255701.0374389\tbest: 255693.1317958 (9573)\ttotal: 6m 34s\tremaining: 17.3s\n",
      "9600:\tlearn: 210325.2968292\ttest: 255698.4854199\tbest: 255693.1317958 (9573)\ttotal: 6m 35s\tremaining: 16.4s\n",
      "9620:\tlearn: 210278.6922187\ttest: 255685.4313566\tbest: 255671.6802765 (9610)\ttotal: 6m 36s\tremaining: 15.6s\n",
      "9640:\tlearn: 210237.2860229\ttest: 255697.9054743\tbest: 255671.6802765 (9610)\ttotal: 6m 37s\tremaining: 14.8s\n",
      "9660:\tlearn: 210179.2058487\ttest: 255687.2417464\tbest: 255671.6802765 (9610)\ttotal: 6m 37s\tremaining: 14s\n",
      "9680:\tlearn: 210121.4158256\ttest: 255673.5268329\tbest: 255668.6832203 (9679)\ttotal: 6m 38s\tremaining: 13.1s\n",
      "9700:\tlearn: 210059.3333057\ttest: 255684.4883032\tbest: 255666.6686967 (9685)\ttotal: 6m 39s\tremaining: 12.3s\n",
      "9720:\tlearn: 210002.4981255\ttest: 255656.5226448\tbest: 255656.5226448 (9720)\ttotal: 6m 40s\tremaining: 11.5s\n",
      "9740:\tlearn: 209956.2326185\ttest: 255651.9053491\tbest: 255647.2060094 (9736)\ttotal: 6m 40s\tremaining: 10.7s\n",
      "9760:\tlearn: 209894.8171868\ttest: 255623.6394304\tbest: 255623.3125643 (9756)\ttotal: 6m 41s\tremaining: 9.84s\n",
      "9780:\tlearn: 209849.0441378\ttest: 255625.1178402\tbest: 255621.3395501 (9761)\ttotal: 6m 42s\tremaining: 9.01s\n",
      "9800:\tlearn: 209800.8676201\ttest: 255599.1416832\tbest: 255598.7503362 (9799)\ttotal: 6m 43s\tremaining: 8.19s\n",
      "9820:\tlearn: 209733.5254012\ttest: 255628.6608261\tbest: 255598.7503362 (9799)\ttotal: 6m 44s\tremaining: 7.37s\n",
      "9840:\tlearn: 209678.5233392\ttest: 255636.8369897\tbest: 255598.7503362 (9799)\ttotal: 6m 44s\tremaining: 6.54s\n",
      "9860:\tlearn: 209612.4676507\ttest: 255627.4307633\tbest: 255598.7503362 (9799)\ttotal: 6m 45s\tremaining: 5.72s\n",
      "9880:\tlearn: 209549.0792128\ttest: 255656.6007511\tbest: 255598.7503362 (9799)\ttotal: 6m 46s\tremaining: 4.89s\n",
      "9900:\tlearn: 209499.2644957\ttest: 255666.2010952\tbest: 255598.7503362 (9799)\ttotal: 6m 47s\tremaining: 4.07s\n",
      "9920:\tlearn: 209431.9668187\ttest: 255635.5549279\tbest: 255598.7503362 (9799)\ttotal: 6m 48s\tremaining: 3.25s\n",
      "9940:\tlearn: 209361.9960360\ttest: 255623.5182496\tbest: 255598.7503362 (9799)\ttotal: 6m 48s\tremaining: 2.43s\n",
      "9960:\tlearn: 209298.5411909\ttest: 255608.3446921\tbest: 255598.7503362 (9799)\ttotal: 6m 49s\tremaining: 1.6s\n",
      "9980:\tlearn: 209242.7600477\ttest: 255602.5892008\tbest: 255598.7503362 (9799)\ttotal: 6m 50s\tremaining: 781ms\n",
      "9999:\tlearn: 209189.8089156\ttest: 255608.5745917\tbest: 255598.7503362 (9799)\ttotal: 6m 51s\tremaining: 0us\n",
      "\n",
      "bestTest = 255598.7503\n",
      "bestIteration = 9799\n",
      "\n",
      "Shrink model to first 9800 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving /Users/patryk/test/kon/AutogluonModels/ag-20250308_144906/models/CatBoost/model.pkl\n",
      "Saving /Users/patryk/test/kon/AutogluonModels/ag-20250308_144906/utils/attr/CatBoost/y_pred_proba_val.pkl\n",
      "\t-255598.7507\t = Validation score   (-root_mean_squared_error)\n",
      "\t436.92s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "\t138805.2\t = Inference  throughput (rows/s | 2500 batch size)\n",
      "Saving /Users/patryk/test/kon/AutogluonModels/ag-20250308_144906/models/trainer.pkl\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 301.25s of the 301.24s of remaining time.\n",
      "\tFitting ExtraTreesMSE with 'num_gpus': 0, 'num_cpus': 11\n",
      "Saving /Users/patryk/test/kon/AutogluonModels/ag-20250308_144906/models/ExtraTreesMSE/model.pkl\n",
      "Saving /Users/patryk/test/kon/AutogluonModels/ag-20250308_144906/utils/attr/ExtraTreesMSE/y_pred_proba_val.pkl\n",
      "\t-242295.1297\t = Validation score   (-root_mean_squared_error)\n",
      "\t44.51s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "\t61908.9\t = Inference  throughput (rows/s | 2500 batch size)\n",
      "Saving /Users/patryk/test/kon/AutogluonModels/ag-20250308_144906/models/trainer.pkl\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 256.46s of the 256.45s of remaining time.\n",
      "\tFitting NeuralNetFastAI with 'num_gpus': 0, 'num_cpus': 11\n",
      "Fitting Neural Network with parameters {'layers': None, 'emb_drop': 0.1, 'ps': 0.1, 'bs': 'auto', 'lr': 0.01, 'epochs': 'auto', 'early.stopping.min_delta': 0.0001, 'early.stopping.patience': 20, 'smoothing': 0.0}...\n",
      "Using 12/12 categorical features\n",
      "Using 56 cont features\n",
      "Automated batch size selection: 256\n",
      "TabularModel(\n",
      "  (embeds): ModuleList(\n",
      "    (0): Embedding(347, 42)\n",
      "    (1): Embedding(54, 15)\n",
      "    (2): Embedding(131, 25)\n",
      "    (3): Embedding(86, 19)\n",
      "    (4): Embedding(12, 6)\n",
      "    (5): Embedding(4, 3)\n",
      "    (6): Embedding(63, 16)\n",
      "    (7): Embedding(5, 4)\n",
      "    (8): Embedding(4, 3)\n",
      "    (9): Embedding(6, 4)\n",
      "    (10): Embedding(250, 35)\n",
      "    (11): Embedding(5, 4)\n",
      "  )\n",
      "  (emb_drop): Dropout(p=0.1, inplace=False)\n",
      "  (bn_cont): BatchNorm1d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layers): Sequential(\n",
      "    (0): LinBnDrop(\n",
      "      (0): Linear(in_features=232, out_features=200, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): LinBnDrop(\n",
      "      (0): Linear(in_features=200, out_features=100, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (2): LinBnDrop(\n",
      "      (0): Linear(in_features=100, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Automated epochs selection: training for 30 epoch(s). Estimated time budget use 114.83 / 255.97 sec\n",
      "Better model found at epoch 0 with _rmse value: 0.7555652856826782.\n",
      "Better model found at epoch 1 with _rmse value: 0.7420515418052673.\n",
      "Better model found at epoch 3 with _rmse value: 0.7229668498039246.\n",
      "Better model found at epoch 7 with _rmse value: 0.7145136594772339.\n",
      "Better model found at epoch 13 with _rmse value: 0.7141387462615967.\n",
      "Better model found at epoch 15 with _rmse value: 0.7079933285713196.\n",
      "Better model found at epoch 17 with _rmse value: 0.6968414187431335.\n",
      "Better model found at epoch 22 with _rmse value: 0.6933932900428772.\n",
      "Better model found at epoch 23 with _rmse value: 0.6933422088623047.\n",
      "Model validation metrics: 0.6933422088623047\n",
      "Saving /Users/patryk/test/kon/AutogluonModels/ag-20250308_144906/models/NeuralNetFastAI/model.pkl\n",
      "Saving /Users/patryk/test/kon/AutogluonModels/ag-20250308_144906/models/NeuralNetFastAI/model-internals.pkl\n",
      "Saving /Users/patryk/test/kon/AutogluonModels/ag-20250308_144906/utils/attr/NeuralNetFastAI/y_pred_proba_val.pkl\n",
      "\t-272652.8596\t = Validation score   (-root_mean_squared_error)\n",
      "\t105.49s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "\t92094.3\t = Inference  throughput (rows/s | 2500 batch size)\n",
      "Saving /Users/patryk/test/kon/AutogluonModels/ag-20250308_144906/models/trainer.pkl\n",
      "Fitting model: XGBoost ... Training model for up to 150.87s of the 150.87s of remaining time.\n",
      "\tFitting XGBoost with 'num_gpus': 0, 'num_cpus': 11\n"
     ]
    }
   ],
   "source": [
    "predictor_custom = TabularPredictor(label=\"sale price\", problem_type=\"regression\", eval_metric=\"root_mean_squared_error\", verbosity=3).fit(X_train, time_limit=960)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wyniki na zbiorze ze wszystkim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: /Users/patryk/test/kon/AutogluonModels/ag-20250308_140219/models/ExtraTreesMSE/model.pkl\n",
      "Loading: /Users/patryk/test/kon/AutogluonModels/ag-20250308_140219/models/KNeighborsDist/model.pkl\n",
      "Loading: /Users/patryk/test/kon/AutogluonModels/ag-20250308_140219/models/LightGBM/model.pkl\n",
      "Loading: /Users/patryk/test/kon/AutogluonModels/ag-20250308_140219/models/NeuralNetFastAI/model.pkl\n",
      "Loading: /Users/patryk/test/kon/AutogluonModels/ag-20250308_140219/models/NeuralNetFastAI/model-internals.pkl\n",
      "Loading: /Users/patryk/test/kon/AutogluonModels/ag-20250308_140219/models/NeuralNetTorch/model.pkl\n",
      "Loading: /Users/patryk/test/kon/AutogluonModels/ag-20250308_140219/models/WeightedEnsemble_L2/model.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'root_mean_squared_error': -2916395.4546280648,\n",
       " 'mean_squared_error': -8505362447775.236,\n",
       " 'mean_absolute_error': -427163.4225973594,\n",
       " 'r2': 0.7440674775120014,\n",
       " 'pearsonr': 0.9038150964796793,\n",
       " 'median_absolute_error': -152291.875}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_custom.evaluate(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wyniki bez outlierow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = TabularPredictor.load(\"AutogluonModels/ag-20250308_144906/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'root_mean_squared_error': -235288.54280152995,\n",
       " 'mean_squared_error': -55360698373.6674,\n",
       " 'mean_absolute_error': -154785.18588567272,\n",
       " 'r2': 0.6408188619843449,\n",
       " 'pearsonr': 0.8010439466664497,\n",
       " 'median_absolute_error': -96012.75}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp.evaluate(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
